{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoJsVjtCMunI"
   },
   "source": [
    "<table align=\"center\">\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"http://introtodeeplearning.com\">\n",
    "        <img src=\"https://i.ibb.co/Jr88sn2/mit.png\" style=\"padding-bottom:5px;\" />\n",
    "      Visit MIT Deep Learning</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/aamini/introtodeeplearning/blob/master/lab1/Part2_Music_Generation.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/aamini/introtodeeplearning/blob/master/lab1/Part2_Music_Generation.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>\n",
    "\n",
    "# Copyright Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bUik05YqMyCH"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.\n",
    "# \n",
    "# Licensed under the MIT License. You may not use this file except in compliance\n",
    "# with the License. Use and/or modification of this code outside of 6.S191 must\n",
    "# reference:\n",
    "#\n",
    "# © MIT 6.S191: Introduction to Deep Learning\n",
    "# http://introtodeeplearning.com\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-97SDET3JG-"
   },
   "source": [
    "# Lab 1: Intro to TensorFlow and Music Generation with RNNs\n",
    "\n",
    "# Part 2: Music Generation with RNNs\n",
    "\n",
    "In this portion of the lab, we will explore building a Recurrent Neural Network (RNN) for music generation. We will train a model to learn the patterns in raw sheet music in [ABC notation](https://en.wikipedia.org/wiki/ABC_notation) and then use this model to generate new music. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 실습에서는, 음악 생성(music generation)을 위한 RNN 구축을 알아보겠습니다. 모델이 ABC notation으로 표현된 악보에서 패턴을 학습하도록 훈련한 후 이 모델을 이용하여 새로운 음악을 생성할 것입니다.\n",
    "\n",
    "- ABC noation이란 악보를 A부터 G까지 문자 표기법을 사용하여 나타낸 것을 말합니다. 번호, 제목, 작곡가, 음표, 길이, 음계 등이 포함되어 있고 각 알파벳 별로 의미하는 것이 정해져 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsvlBQYCrE4I"
   },
   "source": [
    "## 2.1 Dependencies \n",
    "First, let's download the course repository, install dependencies, and import the relevant packages we'll need for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 course 저장소를 다운로드하고, 필요한 것들을 설치한 후, 실습에서 필요한 관련 패키지들을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "riVZCVK65QTH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mitdeeplearning in c:\\users\\mtang\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: gym in c:\\users\\mtang\\anaconda3\\lib\\site-packages (from mitdeeplearning) (0.21.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mtang\\anaconda3\\lib\\site-packages (from mitdeeplearning) (4.59.0)\n",
      "Requirement already satisfied: regex in c:\\users\\mtang\\anaconda3\\lib\\site-packages (from mitdeeplearning) (2021.4.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\mtang\\anaconda3\\lib\\site-packages (from mitdeeplearning) (1.20.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\mtang\\anaconda3\\lib\\site-packages (from gym->mitdeeplearning) (1.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "지정된 경로를 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# Import Tensorflow 2.0\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf \n",
    "\n",
    "# Download and import the MIT 6.S191 package\n",
    "!pip install mitdeeplearning\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "# Import all remaining packages\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "#assert len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ajvp0No4qDm"
   },
   "source": [
    "## 2.2 Dataset\n",
    "\n",
    "![Let's Dance!](http://33.media.tumblr.com/3d223954ad0a77f4e98a7b87136aa395/tumblr_nlct5lFVbF1qhu7oio1_500.gif)\n",
    "\n",
    "We've gathered a dataset of thousands of Irish folk songs, represented in the ABC notation. Let's download the dataset and inspect it: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABC notation으로 표현된 수천 개의 아일랜드 민요(Irish folk songs) 데이터를 수집해놨습니다. 이 데이터셋을 다운로드하고 불러와보겠습니다(inspect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P7dFnP5q3Jve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 817 songs in text\n",
      "\n",
      "Example song: \n",
      "X:1\n",
      "T:Alexander's\n",
      "Z: id:dc-hornpipe-1\n",
      "M:C|\n",
      "L:1/8\n",
      "K:D Major\n",
      "(3ABc|dAFA DFAd|fdcd FAdf|gfge fefd|(3efe (3dcB A2 (3ABc|!\n",
      "dAFA DFAd|fdcd FAdf|gfge fefd|(3efe dc d2:|!\n",
      "AG|FAdA FAdA|GBdB GBdB|Acec Acec|dfaf gecA|!\n",
      "FAdA FAdA|GBdB GBdB|Aceg fefd|(3efe dc d2:|!\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "# colab으로 실행한다면 주석과 같이 작성할 것 \n",
    "# jupyter notebook으로 실행한다면 아래와 같이 작성할 것 \n",
    "# import pattern과 관련해서 수정해주어야 오류가 해결되는 것 같습니다\n",
    "from mitdeeplearning import lab1\n",
    "#songs = mdl.lab1.load_training_data()\n",
    "songs = lab1.load_training_data()\n",
    "\n",
    "# Print one of the songs to inspect it in greater detail!\n",
    "# 하나의 노래를 출력해서 세부사항을 확인해봅시다\n",
    "example_song = songs[0]\n",
    "print(\"\\nExample song: \")\n",
    "print(example_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKF3EHJlCAj2"
   },
   "source": [
    "We can easily convert a song in ABC notation to an audio waveform and play it back. Be patient for this conversion to run, it can take some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABC notation 표기법의 노래를 오디오 파형(audio file)으로 쉽게 변환하여 재생할 수 있습니다. 이 변환에는 시간이 걸릴 수 있기 때문에 조금 기다리길 바랍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vH24yyquwKQ"
   },
   "source": [
    "One important thing to think about is that this notation of music does not simply contain information on the notes being played, but additionally there is meta information such as the song title, key, and tempo. How does the number of different characters that are present in the text file impact the complexity of the learning problem? This will become important soon, when we generate a numerical representation for the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 가지 중요한 점은 이 음악 표기법은 단순히 연주되는 음에 대한 정보만 담고 있는 것이 아니라 추가적으로 노래 제목, 키, 템포와 같은 메타 정보를 포함하고 있다는 것입니다. 텍스트 파일에 존재하는 다양한 문자들이 학습 문제의 복잡성(complexity of the learning problem)에 어떤 영향을 미칠까요? 이는 곧, 텍스트 데이터에서 수치적인(numeric) 표현을 만들어낼 때 중요해질 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 unique characters in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Join our list of song strings into a single string containing all songs\n",
    "# 노래 문자열(string) 목록을 이 모든 노래가 포함된 하나의 단일 문자열로 결합함\n",
    "songs_joined = \"\\n\\n\".join(songs) \n",
    "\n",
    "# Find all unique characters in the joined string\n",
    "# 결합된 노래 묶음 문자열에서 유일한(unique) 단어들을 모두 확인\n",
    "# 데이터셋에는 총 83개의 유일한 문자들이 존재함\n",
    "vocab = sorted(set(songs_joined))\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## 2.3 Process the dataset for the learning task\n",
    "\n",
    "Let's take a step back and consider our prediction task. We're trying to train a RNN model to learn patterns in ABC music, and then use this model to generate (i.e., predict) a new piece of music based on this learned information. \n",
    "\n",
    "Breaking this down, what we're really asking the model is: given a character, or a sequence of characters, what is the most probable next character? We'll train the model to perform this task. \n",
    "\n",
    "To achieve this, we will input a sequence of characters to the model, and train the model to predict the output, that is, the following character at each time step. RNNs maintain an internal state that depends on previously seen elements, so information about all characters seen up until a given moment will be taken into account in generating the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한발 물러서서 우리의 예측 수행 과제(prediction task)에 대해 생각해 봅시다. 우리는 RNN 모델이 ABC 표기 음악에서 패턴을 학습하도록 훈련할 것이며, 그 후 이 모델을 학습한 정보를 바탕으로 새로운 음악 생성(또는 예측)에 사용할 것입니다.\n",
    "\n",
    "이를 분해해서 생각하면, 우리가 모델에게 정말로 요구하는 것은 주어진 문자, 문자들의 시퀀스, 다음 문자로 올 가장 가능성 높은 문자는 무엇인가? 가 됩니다. 우리는 모델이 이 작업들을 수행할 수 있도록 훈련할 것입니다. \n",
    "\n",
    "이를 달성하기 위해서, 모델에게 문자열 시퀀스를 넣을 것이고, 모델이 출력을 예측할 것인데, 이때 말하는 출력은 각 time step에서 다음 문자를 예측하는 것을 말합니다. RNN은 이전에 본 요소에 의존하는 내부 state를 유지하므로, 주어진 순간까지 보여준 모든 문자 정보들은 다음 예측을 생성할 때 고려 대상이 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### Vectorize the text\n",
    "\n",
    "Before we begin training our RNN model, we'll need to create a numerical representation of our text-based dataset. To do this, we'll generate two lookup tables: one that maps characters to numbers, and a second that maps numbers back to characters. Recall that we just identified the unique characters present in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 모델을 훈련하기 전에, 텍스트 기반의 데이터셋을 수치적으로 표현(numerical representation, 숫자 표현)할 필요가 있습니다. 이를 위해서, 두 개의 조회 테이블(lookup tables)를 생성하겠습니다. 하나는 문자를 숫자에 매핑하고, 나머지 하나는 숫자를 다시 문자로 매핑합니다. 우리가 앞서 텍스트에 있는 유일한(unique) 문자들을 확인했던 것을 기억하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "### Define numerical representation of text ###\n",
    "\n",
    "# Create a mapping from character to unique index.\n",
    "# For example, to get the index of the character \"d\", \n",
    "#   we can evaluate `char2idx[\"d\"]`.  \n",
    "# 문자 -> unique index로 매핑\n",
    "# 예를 들어, \"d\"라는 문자의 인덱스는 char2idx[\"d\"]와 같이 작성하여 얻을 것임 \n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "\n",
    "# Create a mapping from indices to characters. This is\n",
    "#   the inverse of char2idx and allows us to convert back\n",
    "#   from unique index to the character in our vocabulary.\n",
    "# index -> 문자로 매핑 \n",
    "# char2idx의 반대 버전이며 index에서 다시 문자로 되돌리는 역할을 할 것임\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "This gives us an integer representation for each character. Observe that the unique characters (i.e., our vocabulary) in the text are mapped as indices from 0 to `len(unique)`. Let's take a peek at this numerical representation of our dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이는 각 문자에 대한 정수 표현을 제공해줄 것입니다. 텍스트 속 유일 문자(즉, 우리가 만든 어휘, 단어장, vocabulary)는 0에서 `len(unique)`까지의 인덱스로 매핑되는지 관찰해봅시다. 데이터셋의 정수 표현(numerical representation)을 살펴봅시다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [python] difference between str() and repr() \n",
    "- 숫자를 문자열로 변환시켜주는 함수입니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FYyNlCNXymwY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '#' :   4,\n",
      "  \"'\" :   5,\n",
      "  '(' :   6,\n",
      "  ')' :   7,\n",
      "  ',' :   8,\n",
      "  '-' :   9,\n",
      "  '.' :  10,\n",
      "  '/' :  11,\n",
      "  '0' :  12,\n",
      "  '1' :  13,\n",
      "  '2' :  14,\n",
      "  '3' :  15,\n",
      "  '4' :  16,\n",
      "  '5' :  17,\n",
      "  '6' :  18,\n",
      "  '7' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n모든 노래 문자열을 벡터화(즉, 정수로)해주는 함수를 작성하시오\\n위에서 본 적절한 매핑을 사용하여 vocab 문자를 각각에 해당하는 인덱스로 변환하세요 \\n\\n참고 : 'vectorize_string' 함수의 결과는 무조건 'N' 요소의 np.array 이여야 합니다. \\n그리고 여기서 'N'은 입력 문자열의 문자의 개수입니다. \\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "모든 노래 문자열을 벡터화(즉, 정수로)해주는 함수를 작성하시오\n",
    "위에서 본 적절한 매핑을 사용하여 vocab 문자를 각각에 해당하는 인덱스로 변환하세요 \n",
    "\n",
    "참고 : 'vectorize_string' 함수의 결과는 무조건 'N' 요소의 np.array 이여야 합니다. \n",
    "그리고 여기서 'N'은 입력 문자열의 문자의 개수입니다. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g-LnKyu4dczc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 22, 13, ..., 22, 82,  2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Vectorize the songs string ###\n",
    "\n",
    "'''TODO: Write a function to convert the all songs string to a vectorized\n",
    "    (i.e., numeric) representation. Use the appropriate mapping\n",
    "    above to convert from vocab characters to the corresponding indices.\n",
    "\n",
    "  NOTE: the output of the `vectorize_string` function \n",
    "  should be a np.array with `N` elements, where `N` is\n",
    "  the number of characters in the input string\n",
    "'''\n",
    "\n",
    "def vectorize_string(string):\n",
    "    # TODO\n",
    "    vectorized_list = []\n",
    "    vectorized_list = ([char2idx[_] for _ in string])\n",
    "    return np.array(vectorized_list)\n",
    "\n",
    "vectorized_songs = vectorize_string(songs_joined)\n",
    "vectorized_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqxpSuZ1w-ub"
   },
   "source": [
    "We can also look at how the first part of the text is mapped to an integer representation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 이제 텍스트 속 첫 번째 파트가 어떻게 숫자로 표현되는지 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "l1VKcQHcymwb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X:1\\nT:Alex' ---- characters mapped to int ----> [49 22 13  0 45 22 26 67 60 79]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
    "# check that vectorized_songs is a numpy array\n",
    "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Create training examples and targets\n",
    "\n",
    "Our next step is to actually divide the text into example sequences that we'll use during training. Each input sequence that we feed into our RNN will contain `seq_length` characters from the text. We'll also need to define a target sequence for each input sequence, which will be used in training the RNN to predict the next character. For each input, the corresponding target will contain the same length of text, except shifted one character to the right.\n",
    "\n",
    "To do this, we'll break the text into chunks of `seq_length+1`. Suppose `seq_length` is 4 and our text is \"Hello\". Then, our input sequence is \"Hell\" and the target sequence is \"ello\".\n",
    "\n",
    "The batch method will then let us convert this stream of character indices to sequences of the desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 단계는 실제로 텍스트를 훈련 중에 사용할 예제 시퀀스로 나누는 것입니다. RNN에 집어넣을 각각의 입력 시퀀스는 텍스트의 `seq_length` 문자를 포함합니다. 또한 각 입력 시퀀스에 대한 타겟(target) 시퀀스를 정의해야 하는데, 이는 RNN이 다음 문자를 예측하기 위한 훈련에 사용됩니다. 각 입력 시퀀스에 대해, 오른쪽으로 문자 하나를 이동시킨 것을 제외하고, 입력에 대응하는 타겟 시퀀스는 동일한 길이의 텍스트를 포함합니다. \n",
    "\n",
    "이를 위해 텍스트를 `seq_length+1`의 덩어리(청크) 단위로 나누겠습니다. `seq_length`가 4 이고 텍스트가 \"Hello\"라고 가정해봅시다. 그렇다면 입력 시퀀스는 \"Hell\"이 되고 타겟 시퀀스는 \"ello\"가 됩니다. \n",
    "\n",
    "그런 다음 batch 방법을 사용하여 해당 문자 인덱스 스트림을 원하는 크기의 시퀀스로 변환할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LF-N8F7BoDRi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PASS] test_batch_func_types\n",
      "[PASS] test_batch_func_shapes\n",
      "[PASS] test_batch_func_next_step\n",
      "======\n",
      "[PASS] passed all tests!\n"
     ]
    }
   ],
   "source": [
    "### Batch definition to create training examples ###\n",
    "\n",
    "def get_batch(vectorized_songs, seq_length, batch_size):\n",
    "  # the length of the vectorized songs string\n",
    "  n = vectorized_songs.shape[0] - 1\n",
    "  # randomly choose the starting indices for the examples in the training batch\n",
    "  idx = np.random.choice(n-seq_length, batch_size)\n",
    "\n",
    "  '''TODO: construct a list of input sequences for the training batch'''\n",
    "  input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
    "  '''TODO: construct a list of output sequences for the training batch'''\n",
    "  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
    "\n",
    "  # x_batch, y_batch provide the true inputs and targets for network training\n",
    "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "  return x_batch, y_batch\n",
    "\n",
    "\n",
    "# Perform some simple tests to make sure your batch function is working properly! \n",
    "test_args = (vectorized_songs, 10, 2)\n",
    "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
    "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
    "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args): \n",
    "   print(\"======\\n[FAIL] could not pass tests\")\n",
    "else: \n",
    "   print(\"======\\n[PASS] passed all tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_33OHL3b84i0"
   },
   "source": [
    "For each of these vectors, each index is processed at a single time step. So, for the input at time step 0, the model receives the index for the first character in the sequence, and tries to predict the index of the next character. At the next timestep, it does the same thing, but the RNN considers the information from the previous step, i.e., its updated state, in addition to the current input.\n",
    "\n",
    "We can make this concrete by taking a look at how this works over the first several characters in our text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 각각의 벡터에 대해, 각 인덱스는 하나의 단일 time step으로 처리됩니다. 그러므로, time step 0의 입력의 경우, 모델은 시퀀스의 첫 번째  문자에 대한 인덱스를 받고, 다음 문자의 인덱스를 예측하려고 할 것입니다. 그 다음 time step에서도 동일하게 반복하지만, RNN은 이전 step에서의 정보, 즉 현재 입력 외에 업데이트 된 state를 고려합니다. \n",
    "\n",
    "우리는 텍스트의 첫 몇개의 문자들로 이것이 어떻게 동작하는지 살펴보고 구체화해 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0eBu9WZG84i0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0\n",
      "  input: 1 (' ')\n",
      "  expected output: 43 ('R')\n",
      "Step   1\n",
      "  input: 43 ('R')\n",
      "  expected output: 70 ('o')\n",
      "Step   2\n",
      "  input: 70 ('o')\n",
      "  expected output: 56 ('a')\n",
      "Step   3\n",
      "  input: 56 ('a')\n",
      "  expected output: 59 ('d')\n",
      "Step   4\n",
      "  input: 59 ('d')\n",
      "  expected output: 1 (' ')\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
    "\n",
    "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
    "    print(\"Step {:3d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## 2.4 The Recurrent Neural Network (RNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "Now we're ready to define and train a RNN model on our ABC music dataset, and then use that trained model to generate a new song. We'll train our RNN using batches of song snippets from our dataset, which we generated in the previous section.\n",
    "\n",
    "The model is based off the LSTM architecture, where we use a state vector to maintain information about the temporal relationships between consecutive characters. The final output of the LSTM is then fed into a fully connected [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer where we'll output a softmax over each character in the vocabulary, and then sample from this distribution to predict the next character. \n",
    "\n",
    "As we introduced in the first portion of this lab, we'll be using the Keras API, specifically, [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential), to define the model. Three layers are used to define the model:\n",
    "\n",
    "* [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding): This is the input layer, consisting of a trainable lookup table that maps the numbers of each character to a vector with `embedding_dim` dimensions.\n",
    "* [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): Our LSTM network, with size `units=rnn_units`. \n",
    "* [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): The output layer, with `vocab_size` outputs.\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리는 ABC 음악 데이터셋에 맞춰 RNN 모델을 훈련하고 훈련한 모델로 새로운 음악을 만들 준비를 마쳤습니다. 이전 섹션에서 생성한 데이터셋의 음악 조각을 사용하여 RNN을 훈련할 것입니다. \n",
    "\n",
    "모델은 LSTM 구조를 기반하는데, 이 구조는 연속되는 문자들 사이의 시간 관계(temporal relationships)에 대한 정보를 유지하는 state 벡터를 사용합니다. LSTM의 최종 출력은 fully-connected `Dense` layer로 넘겨지는데, 여기서 vocabulary의 각 문자에 대해 softmax를 계산하고(출력하고) 이로부터 만들어진 불포에서 샘플을 추춘하여 다음 문자를 예측합니다. \n",
    "\n",
    "이번 실습의 첫 부분에서도 소개했듯이, 우리는 모델을 정의하기 위해 keras API [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential)를 사용합니다. 모델을 정의하기 위해 세 개의 레이어가 사용됩니다. \n",
    "\n",
    "* [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) : 입력 레이어, 각 문자의 숫자들을 `embedding_dim`차원의 벡터로 매핑하는 훈련 가능한 lookup 테이블로 구성됨 \n",
    "* [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): `units=rnn_units` 크기의 LSTM 신경망\n",
    "* [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): `vocab_size` 출력이 있는 출력 레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlaOqndqBmJo"
   },
   "source": [
    "### Define the RNN model\n",
    "\n",
    "Now, we will define a function that we will use to actually build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 실제로 만들기 위해 사용할 함수를 정의하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8DsWzojvkbc7"
   },
   "outputs": [],
   "source": [
    "def LSTM(rnn_units): \n",
    "  return tf.keras.layers.LSTM(\n",
    "    rnn_units, \n",
    "    return_sequences=True, \n",
    "    recurrent_initializer='glorot_uniform',\n",
    "    recurrent_activation='sigmoid',\n",
    "    stateful=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbWU4dMJmMvq"
   },
   "source": [
    "The time has come! Fill in the `TODOs` to define the RNN model within the `build_model` function, and then call the function you just defined to instantiate the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "때가 됐습니다! `TODOs`를 채워 `build_model`함수 내에서 RNN 모델을 정의한 다음, 정의한 함수를 호출하여 모델을 인스턴스화합시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "### Defining the RNN Model ###\n",
    "\n",
    "'''TODO: Add LSTM and Dense layers to define the RNN model using the Sequential API.'''\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    # Layer 1: Embedding layer to transform indices into dense vectors \n",
    "    #   of a fixed embedding size\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "\n",
    "    # Layer 2: LSTM with `rnn_units` number of units. \n",
    "    # TODO: Call the LSTM function defined above to add this layer.\n",
    "    LSTM(rnn_units),\n",
    "\n",
    "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
    "    #   into the vocabulary size. \n",
    "    # TODO: Add the Dense layer.\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Build a simple model with default hyperparameters. You will get the \n",
    "#   chance to change these later.\n",
    "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "### Test out the RNN model\n",
    "\n",
    "It's always a good idea to run a few simple checks on our model to see that it behaves as expected.  \n",
    "\n",
    "First, we can use the `Model.summary` function to print out a summary of our model's internal workings. Here we can check the layers in the model, the shape of the output of each of the layers, the batch size, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리의 모델이 예상대로 잘 작동하는지 확인하기 위해 몇 가지 간단한 검사를 해보는 것은 항상 좋은 생각입니다. \n",
    "\n",
    "우선, `Model.summary` 함수를 사용하여 모델의 내부 작동에 대한 summary를 출력할 수 있습니다. 이로부터 모델 내부의 레이어, 각 레이어의 출력 형태(shape), 배치 사이즈 등을 확인해 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RwG1DD6rDrRM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (32, None, 256)           21248     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (32, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, None, 83)            85075     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,353,299\n",
      "Trainable params: 5,353,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xeDn5nZD0LX"
   },
   "source": [
    "We can also quickly check the dimensionality of our output, using a sequence length of 100. Note that the model can be run on inputs of any length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 또한 길이 100의 시퀀스를 사용하여 출력물의 차원도 빠르게 확인해 볼 수 있습니다. 모델은 어떤 길이의 입력에서도 작동할 수 있음을 알아두세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:       (32, 100)  # (batch_size, sequence_length)\n",
      "Prediction shape:  (32, 100, 83) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
    "pred = model(x)\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT1HvFVUGpoE"
   },
   "source": [
    "### Predictions from the untrained model\n",
    "\n",
    "Let's take a look at what our untrained model is predicting.\n",
    "\n",
    "To get actual predictions from the model, we sample from the output distribution, which is defined by a `softmax` over our character vocabulary. This will give us actual character indices. This means we are using a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) to sample over the example prediction. This gives a prediction of the next character (specifically its index) at each timestep.\n",
    "\n",
    "Note here that we sample from this probability distribution, as opposed to simply taking the `argmax`, which can cause the model to get stuck in a loop.\n",
    "\n",
    "Let's try this sampling out for the first example in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자, 우리의 훈련시키지 않은 모델이 무엇을 예측할지 확인해봅시다. \n",
    "\n",
    "모델의 실제 예측을 얻기 위해서, 우리는 문자 vocabulary를 `softmax`로 정의한 출력 분포에서 샘플을 추출해야 합니다. 이는 우리에게 실제 문자 인덱스틀 제공합니다. 즉, 범주형 분포([categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) )을 사용하여 예제 예측을 샘플로 추출함을 의미합니다. 이로써 각 time step에서 다음 문자(특히나 그 인덱스에서의)에 대한 예측을 하게 됩니다. \n",
    "\n",
    "여기서는 단순히 `argmax`를 취하는 대신 확률 분포에서 표본을 추출합니다. (그리고 argmax는 모델이 루프에 빠지게 만들 수 있습니다?)\n",
    "\n",
    "첫 번째 예시 batch에서 샘플링을 실행해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 17, 61, 29, 17, 46, 15, 55, 24, 42, 71, 81, 77, 38, 37, 65, 24,\n",
       "       30, 48, 39, 77, 54, 28, 75, 66, 24, 82, 27, 19,  1, 13, 16, 27, 23,\n",
       "       12, 38, 62,  4, 36, 79, 41, 26, 20, 17, 26, 64, 76, 24, 23, 37,  5,\n",
       "       24, 67, 79, 57, 80, 66, 43, 66, 31, 46,  4, 17, 59, 59,  5, 71, 36,\n",
       "       56, 38, 18, 66, 71, 65, 72, 57, 19, 48, 39,  0, 35, 59, 40,  0, 67,\n",
       "       40, 54,  7, 61, 25, 57, 71, 34, 28, 44, 81, 10, 65, 36, 15],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfLtsP3mUhCG"
   },
   "source": [
    "We can now decode these to see the text predicted by the untrained model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이들을 디코딩하여 훈련되지 않은 모델이 예측한 텍스트를 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " ':dc-setdance-28\\nM:6/8\\nL:1/8\\nK:D Major\\nded fed|cBA cec|BcB fdB|BcB fdB|!\\nded fed|cBA cec|ABA ecA|ABA '\n",
      "\n",
      "Next Char Predictions: \n",
      " \"95fD5U3_=QpzvMLj=EWNv^Ctk=|B7 14B<0Mg#KxPA85Aiu=<L'=lxbykRkFU#5dd'pKaM6kpjqb7WN\\nJdO\\nlO^)f>bpICSz.jK3\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEHHcRasIDm9"
   },
   "source": [
    "As you can see, the text predicted by the untrained model is pretty nonsensical! How can we do better? We can train the network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러분들도 볼 수 있듯이, 훈련되지 않은 모델의 예측 텍스트는 굉장히 터무니없네요! 어떻게 해야 할까요? 신경망을 훈련시켜봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## 2.5 Training the model: loss and training operations\n",
    "\n",
    "Now it's time to train the model!\n",
    "\n",
    "At this point, we can think of our next character prediction problem as a standard classification problem. Given the previous state of the RNN, as well as the input at a given time step, we want to predict the class of the next character -- that is, to actually predict the next character. \n",
    "\n",
    "To train our model on this classification task, we can use a form of the `crossentropy` loss (negative log likelihood loss). Specifically, we will use the [`sparse_categorical_crossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) loss, as it utilizes integer targets for categorical classification tasks. We will want to compute the loss using the true targets -- the `labels` -- and the predicted targets -- the `logits`.\n",
    "\n",
    "Let's first compute the loss using our example predictions from the untrained model: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 모델을 훈련시킬 시간입니다!\n",
    "\n",
    "이때, 우리는 다음 문자를 예측하는 문제를 일반적인 분류 문제(classification)로 생각해 볼 수 있습니다. RNN의 이전 state와 주어진 time step에서의 입력을 고려할 때, 우리는 다음 문자에 대한 class를 예측하고 싶어합니다. 즉, 다음 문자를 실제로 예측하는 것이 되는 것이죠. \n",
    "\n",
    "이 분류 작업에 대해 모델을 훈련시키기 위해, 우리는 `crossentropy` loss 형태를 사용할 수 있습니다. 특히나, 우리는 [`sparse_categorical_crossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/backend/sparse_categorical_crossentropy) loss를 사용할 것인데, 해당 loss는 범주형 분류 작업을 위해 정수 타겟을 사용하기 때문입니다. 우리는 실제 타겟(`labels`)과 예측 타겟(`logits`)을 사용하여 loss를 계산하길 원합니다. \n",
    "\n",
    "먼저 훈련시키지 않은 모델의 예시 예측을 사용해 loss를 계산해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (32, 100, 83)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.4177337\n"
     ]
    }
   ],
   "source": [
    "### Defining the loss function ###\n",
    "\n",
    "'''TODO: define the loss function to compute and return the loss between\n",
    "    the true labels and predictions (logits). Set the argument from_logits=True.'''\n",
    "def compute_loss(labels, logits):\n",
    "  loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True) # TODO\n",
    "  return loss\n",
    "\n",
    "'''TODO: compute the loss using the true next characters from the example batch \n",
    "    and the predictions from the untrained model several cells above'''\n",
    "example_batch_loss = compute_loss(y, pred)\n",
    "\n",
    "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Seh7e6eRqd7"
   },
   "source": [
    "Let's start by defining some hyperparameters for training the model. To start, we have provided some reasonable values for some of the parameters. It is up to you to use what we've learned in class to help optimize the parameter selection here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련을 위해 하이퍼파라미터들을 정의해봅시다. 시작하기 앞서 우선, 일부 파라미터에 대해 합리적인 값들을 제공했습니다. 수업 시간에 배운 내용을 사용하여 여기서 파라미터 선택을 최적화하는 것은 여러분에게 달려있습니다! (최적의 파라미터 찾기) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "JQWUUhKotkAY"
   },
   "outputs": [],
   "source": [
    "### Hyperparameter setting and optimization ###\n",
    "\n",
    "# Optimization parameters:\n",
    "num_training_iterations = 2000  # Increase this to train longer\n",
    "batch_size = 4  # Experiment between 1 and 64\n",
    "seq_length = 100  # Experiment between 50 and 500\n",
    "learning_rate = 5e-3  # Experiment between 1e-5 and 1e-1\n",
    "\n",
    "# Model parameters: \n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256 \n",
    "rnn_units = 1024  # Experiment between 1 and 2048\n",
    "\n",
    "# Checkpoint location: \n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cu11p1MKYZd"
   },
   "source": [
    "Now, we are ready to define our training operation -- the optimizer and duration of training -- and use this function to train the model. You will experiment with the choice of optimizer and the duration for which you train your models, and see how these changes affect the network's output. Some optimizers you may like to try are [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam?version=stable) and [`Adagrad`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad?version=stable).\n",
    "\n",
    "First, we will instantiate a new model and an optimizer. Then, we will use the [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) method to perform the backpropagation operations. \n",
    "\n",
    "We will also generate a print-out of the model's progress through training, which will help us easily visualize whether or not we are minimizing the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 우리의 훈련 작업(최적화와 훈련 기간)을 정의하고 이 함수를 사용하여 모델을 훈련할 준비가 되었습니다. 여러분들은 optimizer와 모델을 훈련할 기간을 선택함으로써 실험해볼 수 있고, 이러한 변화들이 신경망의 출력에 어떤 영향을 주는지를 볼 수 있습니다. 여러분들이 시도해볼 만한 몇몇 optimizer로는 [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam?version=stable) 과 [`Adagrad`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad?version=stable). 가 있습니다. \n",
    "\n",
    "먼저, 우리는 새로운 모델과 optimizer를 예시로 들 것 입니다. 그 후, 역전파 작업을 수행하기 위해 [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape)를 사용합니다. \n",
    "\n",
    "또한 우리는 훈련 동안 모델의 진행 상황을 출력하여 loss를 최소화하고 있는지에 대한 여부를 쉽게 시각화 해보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "F31vzJ_u66cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuhUlEQVR4nO3dd3wUZf4H8M83CYGETgg1QAQp0ktAkCJFKYIVFXs5PU/Phnoi/jwURU4sqKfe6dk7imI7ORFEitJDCb0TIFISagIhpD2/P2Zmd7ZmN9nZTWY/79eLV3ZnZ2ee7IbvPPOU7yNKKRARkf3ERLoARERkDQZ4IiKbYoAnIrIpBngiIptigCcisqm4SBfArGHDhio1NTXSxSAiqjJWr159RCmV7O01SwO8iGQCyANQAqBYKZXmb//U1FSkp6dbWSQiIlsRkb2+XgtHDX6IUupIGM5DREQmbIMnIrIpqwO8AjBXRFaLyF3edhCRu0QkXUTSc3JyLC4OEVH0sDrA91dK9QQwCsC9IjLIfQel1NtKqTSlVFpystd+AiIiKgdLA7xS6oD+MxvAtwD6WHk+IiJysizAi0hNEaltPAYwHMBGq85HRESurBxF0xjAtyJinOdzpdQcC89HREQmlgV4pdRuAN2sOr7ZjsN5OHa6EOe3TgrH6YiIqoRKNZO1vC5+ZTEAIHPa6AiXhIio8uA4eCIim2KAJyKyKQZ4IiKbYoAnIrIpBngiIptigCcisikGeCIim2KAJyKyKQZ4IiKbYoAnIrIpBngiIptigCcisikGeCIim2KAJyKyKQZ4IiKbYoAnIrIpBngiIptigCcisikGeCIim2KAJyKyKQZ4IiKbYoAnIrIpBngiIptigCcisikGeCIim7JVgFdKRboIRESVhq0CfCnjOxGRg60CPGvwREROtgrwrMETETnZKsArMMITERlsFeCzc89GughERJWGrQL8S3O3RboIRESVhq0CPNvgiYicbBXgOYqGiMjJZgE+0iUgIqo8bBXgSxnhiYgcGOCJiGzKVgGe8Z2IyMnyAC8isSKyVkR+tPpcHEVDROQUjhr8gwC2WHmCTs3qAOAoGiIiM0sDvIikABgN4F0rzxMbIwDYBk9EZGZ1Df5VABMAlPraQUTuEpF0EUnPyckp10lE/8kmGiIiJ8sCvIiMAZCtlFrtbz+l1NtKqTSlVFpycnJ5z6Udq1zvJiKyJytr8P0BXCYimQC+ADBURD614kR6Cw3b4ImITCwL8Eqpx5VSKUqpVADXAfhVKXWTFeeKEbbBExG5s8U4eD2+o9RnSz8RUfSJC8dJlFILASy06vjONnjW4ImIDPaowes/OYqGiMjJFgHeaINnJysRkZM9Arz+W7AGT0TkZIsAP2FEBwBAn3MaRLgkRESVhy0CfEc9F03N+NgIl4SIqPKwRYA32uBLOEySiMjBJgFe+8mJTkRETrYI8CICEY6iISIys0WAB7RmGo6iISJyslGAB0pYgycicrBRgBe2wRMRmdgqwCultcOnTpyN1ImzcTK/KNLFIiKKGNsE+KKSUhw9VQhzJX5nzqnIFYiIKMJsE+CLSxVmrclyyyfJJhsiil62CfAGczs8R9UQUTSzd4BnhCeiKGa7AN/+73McjxneiSia2S7Am3HYJBFFM1sHeFbhiSia2SbAN6gZ77GNTfBEFM1sE+Cv7pXisY2LcBNRNLNNgI8zcgabFLMKT0RRzDYB/q9DzvXYVlzCAE9E0cs2Ab5W9Tj0bFnPZVtJKZd4IqLoZZsADziX7jMUsQZPRFHM1gG+mDV4IopitgrwbvGdbfBEFNVsFeAHt2/k8pyjaIgomtkqwN99YWuX5wzwRBTNbBXgxb0NvoRt8EQUvWwV4N2xDZ6IopntAvy1ac6UBWyiIaJoZrsAn1I/0fGYTTREFM1sF+DNrfBFrMETURSzXYA3x/TDJwsiVxAiogizXYAvLClxPP4yfX8ES0JEFFm2C/Bni1zb3XPyzkaoJEREkWW7AF/o1rHae+ovWLw9J0KlISKKHMsCvIjUEJGVIpIhIptE5GmrzmXWNaWex7Z1+0+E49RERJWKlTX4swCGKqW6AegOYKSI9LXwfACAsT2b47cJQ1y2lSqOpiGi6BNn1YGVUgrAKf1pNf2f5ZFWRNCiQaLLNo6WJKJoZGkbvIjEisg6ANkA5imlVnjZ5y4RSReR9Jwci9rKWYMnoihkaYBXSpUopboDSAHQR0Q6e9nnbaVUmlIqLTk52ZJysAZPRNEooAAvIjVFJEZ/3E5ELhORaoGeRCl1AsBCACPLU8iKYhs8EUWjQGvwiwHUEJHmAOYDuB3Ah/7eICLJIlJPf5wA4CIAW8td0gpgDZ6IolGgAV6UUvkArgLwulLqSgAdy3hPUwALRGQ9gFXQ2uB/LH9Ry0+xBk9EUSjgAC8i/QDcCGC2vs3vCByl1HqlVA+lVFelVGel1DMVKWiwtk5xtga5LwRCRBQNAg3w4wE8DuBbpdQmEWkNYIFlpQqBGtViHY8Z34koGgU0Dl4ptQjAIgDQO1uPKKUesLJgocT4TkTRKNBRNJ+LSB0RqQlgM4BtIvKotUULHdbgiSgaBdpE01EplQvgCgD/A9ASwM1WFSrU4mNjy96JiMhmAg3w1fRx71cA+F4pVYQwpB0Ilfg42yXNJCIqU6CR7z8AMgHUBLBYRFoByLWqUKEWy/hORFEooNCnlHpNKdVcKXWJ0uwFMKTMN1YSX6/OinQRiIjCLtBO1roi8rKRFExEpkOrzVcJ2w+fQgmnsxJRlAm08eJ9AHkArtX/5QL4wKpCWaHIbaUnIiK7CzTAt1FKPaWU2q3/expAaysLFgpLJg51PGaAJ6JoE2iAPyMiA4wnItIfwBlrihQ6TerUcDwuKmETDRFFl0BXdLobwMciUld/fhzArdYUKXRiTBOcWIMnomgT6CiaDH1t1a4AuiqlegAYWsbbIs6cZOxwbgEemLEW87ccjmCJiIjCJ6gR4kqpXH1GKwA8bEF5LPPIzAz8kHEAd3yUHumiEBGFRUWmAFWpDC/H84siXQQiorCqSICvUr2WR06djXQRiIjCym8nq4jkwXsgFwAJlpSIiIhCoqxVmWqHqyBERBRaTMNFRGRTDPBERDbFAE9EZFO2D/AtGrAvmIiik+0D/OJHq0zaeiKikLJ9gBeuuE1EUcr2AR4A/nVDz0gXgYgo7KIiwI/u2jTSRSAiCruoCPBERNEoagP87R+sxKWv/x7pYhARWSbQBT9spbikFAu25US6GERElorKGvwT326MdBGIiCwXlQH+y/T9HtvmbDyEfs/NR2Exl/YjInuIygDvzVM/bMTBkwU4drow0kUhIgoJBngAWcfzcTiXC4IQkb1EfYDPLSjCgOcXRLoYREQhFzUB/vmxXRAf6/nrdp08NwKlISKyXtQE+HG9WwY0o1VVraVmiYh8ipoADwBje6ZEughERGETVQF+QNuGeOumXpEuBhFRWERVgAeAwpKyx7kXFJUgO7cgDKUhIrKOZQFeRFqIyAIR2SIim0TkQavOFYyCopIy97n5vRXo84/5YSgNEZF1rMxFUwzgEaXUGhGpDWC1iMxTSm228JxlOltGgFcKWJV5PEylISKyjmU1eKXUQaXUGv1xHoAtAJpbdb5AFRT5b6LhGBoisouwtMGLSCqAHgBWeHntLhFJF5H0nBzrMzxeUsZQydJShngisgfLA7yI1AIwC8B4pVSu++tKqbeVUmlKqbTk5GSri4Pm9RIC3ve5/23ByfwiC0tDRGQdSwO8iFSDFtw/U0p9Y+W5QmXq7C2Ox/9ZvBvP/bTFz95ERJWXlaNoBMB7ALYopV626jyhNmfTIZfnZQ2rnLPxEOZsPGhlkYiIysXKGnx/ADcDGCoi6/R/l1h4voi4+9PVuPvTNZEuBhGRB8uGSSqlfgcgVh3fjj5csgd5BcW4f1jbSBeFiGwgKtdkrawm/1ebIsAAT0ShwABfDvmFxTh2uhCLtx+JdFGIiHyKygD/yMXtsHTXUeScOoud2af87iteWpk6Pvmz3/fsPXoan63Yh4kjOyAmhq1URBQZUZdsDNCaQGbc1Rc1q5d9fTtySlvKb/IPm7Byz7GAjn/Pp2vw9uLd2FHGxYOIyEpRGeANcQHUrhdtz4FSCh8uzcS1/1lW5v5vLdqFzQe1+VylirNiiShyojrAxwbYfFJsSl+wdJf3dnejqeeVedsd27YczMXs9f7HyN/50SqkTpwNxYsBEYVYVAf4QGrwAFBc4gy+h056zxP/zI+eSTIfnpmBez/3PkZ+6uzN6P7MXPyyJRsAcM7j/wuoLEREgYrqAG/U4OslVvO7392frnY8fnhmhtd9Fm/XEqUFWg9/57c9OOEjz83T/90U4FGIiHxjgAcwqnMTv/st2h54lsuiAFaMKssHSzJ9vlZQVIIzhWUvWkJEFNUB3miiOX02NAFzy8FceGtKPxzC5f/6TP0F5z05x2Xb/mP5SHt2HvYdzQ/ZeYio6ovqAH9j31YAgPZNaofkeKP++ZvX7ef/Yz5+NiUx23PkdFDH/WZNFp7RZ7nmFhS7vHbyTBEGvrAAR04VYmb6/iBL7OmXzYdx4MSZCh+HiCIvqgP8kPaNkDltNOonxrtsz5w2OuTnWrf/hOPxVf9eEtR7H56ZgfeX7PH62n8zDjgeF4dgsZI7P07HZW8EVz4iqpyiOsAbLmiTBAAY2akJ6pfR4VpeTevWwO4cbSjl8QAWEXnvd+8B3V1ugfNYJaXe2/9P5hdh5KuLsTM7L6BjGpO7Qi2voAjHTxdacmwi8sQADyC1YU1kThuNt27uhbVPDgcAvHRNt5Ce48nvN2Ho9EWY9tPWgPaf4mXYZVmKSxUemZmBEa8sRkFRCRZs04ZgLtiWja2H8vDa/J3IKyjC2eLA+xzmbjqE7LzQ9CH0e+5X9Jgyz+tri7fnYEPWyZCch4g0DPA+XN0rBR/9qU/Ij/vWol0hP6ahpFRh1posbDuch6f/uwm3f7AKmw+4rpLYZfJcXPtW2TNyAW3Ezl2frMYt760MSflOnS32+dot76/EpW/8HpLzhMuSnUewbNfRSBeDyKeoTDYWqPaNQ9P5Wl5FJaV+x8Qv3JaNF+ZsM+3vbIPfla115OYVFEH0+VzGqxk+asrus2mNNv39x8I3Oic7twCFJaVIqZ8YtnOW143vamvIW9FnQxQKrMH7UdYEKKs9/9NWfLp8n+O5e9v4vxbsdHk+Y6VzX6WHc5HAs1m6D/Es0S8YRkbM/cfykV/ouxYeCn3+MR8Dnl9g6TmIogUDvB81qsVG9PzvunW0DnrBGfhSJ87GqszjPt9rvHb/jDU4ckrr2DSPuPHGnBzt2OlCFOmdtnkFxcgvLMbAFxbgtg9WlVnuR2Zm4IlvN5S5HxFZiwG+CskvxwzWw7lnA+6wNVfgp/20xWVW7j69mSaQlMmz1mThsxX7cCK/EBe/vKjMnPuV0eq9x5E6cbZj5BNRVcQAX4b3b0uLdBEsZQSy7NwCjxq8Ocmat4VPzAqKSlBY7DpMc/6WbOzIPoV/uzUlWUUphazjoekv+G7tHwCABdty8OyPmy0bOkqVx/HThVWyMuIPA3wZhnZoHOkiWGL6XK1z1phAtWLPMZc2+OJS5TOvjrkz9u/fbcDj32xAh0lzMOzlhS77Gc3/4cqL/9mKfRjw/AJkmCaVlZdR9oXbsvHu73vw1A9MAGd3w19djIteXhTpYoQUA3w5jezUBF/d3Q+1/awKVadG5R2k9PqvWq26VB8pE+PWGVuqXFMjZx51plcwT8L6dPk+R+fu/mNnHMcDnDnyw5XpPj1Taz7afaTitTDj0zAuckXFFU8iFypfpe8P+I7ibLHnnRV5l5Nnv7s0BvgATL+mG168uqvLtm4t6qF3agNseHoEfrivv8d7nh/bBQv+NjhMJSyfZbuOokQPyArKpaatlMJR06zTv3ziTJm8KvMYSksVlu70XPzEPJb93wu1Mf9lZVDY+EfFJjj9N+MAZq8/6LhI+ZjQ69WzP25G6sTZHtuN0UdG2YMYjGSprOP5ePTr9fjrp97XGXDX/u9zMHT6wpCcu6RUYcVujvuvShjgAzC2VwquSWuBt27qhYs7ak025mDoXvutUyMO16a1QFKt6mEtZ7Cuf2e5I4Dd9/lal8XEd2afwv0z1np938+bDqP1//0PN+jjwM02uU2sArQA/ON65wiemaucSdEmfJ2BMa+XPcFpZvp+pE6c7bU2ev+MtdrCKuVoEjJGKvnKxGk0R/286XBAaZp/XH8A7Z74CQVFoclQ+p9Fu3CfadGYs/rvb67BK6Xw7doslya14pJSnMjXLtBZx0OTPO6933dj3NvL8duOwNNnU2QxwAdhZOcmaNe4FgDXdmj32l3z+olBjT+PJF/B8KCPlavK677PnReLCbPWAwBen78DM9OzvO7/8JfrXLJuGike8gp85/H5Zo3WMfrzpsM+93ll3nakTpzt0pQEAINedB1775gcZtrt3d92+zyuuZyFJaXIyTuLW99fiYEv/IqzxSUu5/vjxJmA1w147qet+HH9Qcffm+PvTi/f6bPFmLPxEB76MgOTvtvoCOqTvt+I7s94TwtRXnv1i2BmiNJSz99yOGQXQvKOAT5IMW637uZthrRW9R2Px/ZMQefmdcJStvL4dWt2RM572Ru/Y7pp/Vp336z9A0NeWojJP2xCcUmp40IkIpjy42b0n/YrJvvo+PxlizPAK6Xw5PcbMfmHTdj4x0n8c/4OAECJlwvbzuxTOHlGu4AYo4bMewWSrdN82EXbc7D/2Bm0//scPDt7CwDgRH4h+k/71ZH+2Zf5Ww67NB39rjeHGUWIEcGs1Vno9NTPWKt3Kn+xaj+6PzMPq/cew/fr/M95MGw9lIvUibO93sHc/N4KXPPWUsfzBH1eSEEIFpzZ+MdJ3PFRelhXLzt2utAlOV80YIAPklEzLyn1bKJp17gW5owfiEljOjpem35tN3z3V882+mi3PsDEYh8uzcSKPcccn/d/Fu3Ce7/vwR8nzuDDpZk+3/fJsky8+st2fL06Cx8v24sPl2a6NAWVlCrM3+Ja07/o5UWOVM7eRgAZ3/NHSzM9mik2ZJ3Ep8v3Op6738B9vlJ7zcgk6r5K2Pu/78Gs1VmOmv7sDa6LtRvLOypHgIej2cs9lcTYN5eVMajV6Wv9DmrOJs/F4X/bccTrZLozIah15+oX0kDXRpi9/iDW7vM9sS8QPafMQ9qzvwS8f0mpQurE2QHduXl734s/B5ZY0EqVd5hHJXVJlyZ4bf4OjDQt8+cMBkCHJp619dgYQc+W9bBm3wmP1+Y9NAgZWScxolNj3PPpGkdNjZwS4mMdge0/iwP7zzbpe/81wxV7juGOj9I9tu/K0QKOESDNNfJYvTrkbcik0bncrG4Nr+cz7giMPoRqsc4QvOnAScei7YdyC3DvkHORdcx7u7kRNATiWImsTg3PlBqn/dSyNx/IRZtGNVE9LtaxbGUgLUZGf0VJCNYdgJcmMH+MxesrmvcnmBFFRtbV6XO3486BrQN+n7MyshuPjujgd98zhSU4nFuA1IY1Az5+MFiDD1KHJnWQOW00zmvqDOQxZXTuiQimjXUdhfPYSO2Lb1ovAVf3SkHtGtWQUj/BmkJXcV+vzvKbibI8bn0/sAyZ5oVaAulXOaD3Xbjva9R6jZ+7ck7jk2WZSJ04G6Nfc95ZvPizNj9hZabrjOFPlu/F7PUH8cuWbP34cKSSqFEt8P/Gh04W4JLXfsNT+gXQCPBHg5jI9c/5O7Bs11GP95SWap297heAvUdPY9uhPMxYuQ/F+pXEuOCt2HMMj329Hs/+uNmjX6SqMvJABfLb/PnjdAx+aaFlZWGADwFxT9cYgLsvbI09z12CWqZx9EM7NHLZp2WD8mdUvKxbs3K/t7L5fMU+n699vdp7J21F7Mw+5ZEHCHAGw4ooNlWVfd1luGf1BLQUEfeaRtNsPZSHtfodYUwQ5TpxRuuE/UIfyWT8Tu/+vgfrs05g2a6jyC8sLrOP4Pp3lqOXW3PHZyv34aEvM/DZir0u2y98cSFGvLoYj3+zAR8t014zF/nL9P149/c9yMg6EfDv4U/W8fyAO7G9MT7/8l5vjGG6gYzmMu7YvwrBcpveMMCHQFJNbcm/4Z2a+NzH/bsWEY9a3vBOTbDyiWHYMXUUdv/jEtw35Nxyl2mEqSzPXtEZ791qz5QLf/sqI+THXOZjrHesiNfgO2+z56idVV5y9lz+ryUBdfIFG1jKSiPhcmy3uGe+aF32xhJc/85yvLN4j8sSkf7SRZ88U4SeU+ZhVeYxR43+SJ7rEE4zY5RPRUaZ5RYU4ctV+zDha8/vPq+gCAOeX+CR7M5IPeH+2BvjDqS8TVF/6GsaBzOB+/k51rTXM8CHQL3EeKyddDEeHdHe5z6J8YFlpmxUuwaqxcYgJkZwbe8WAZfhpWu64d4hbRzPL+miBfhRnZvgpr6t0LQum38CVeyj9nfg5Blc+OJCj+1//tizLX/8l+s8tmXsP4E/fei5r8f5g5mpBeDjZZkB7bd891GXfQ+ePOPoczBzX/px4AsLsO2Q9+UeN2SdxLHThXjFx4ioJ77b6PL89V934oU5Wys0cazr5Ll4bNYGzEzPwhu/7nB5zZirsGBbDn7acNCxTKX5+xj/5Tq/q5SVuA1JdS9rbkGR3+Gd5Ul3EJJ+DS8Y4EOkfs14v7fwLRoklmuFqOb1yg7MsTGCq3ul4JGLnRcYEcGOqaPwrxt6AvCd2z41yX8z0NW9UoIorT087aN54qOlmY6smlYyFmsJVKCLrV/39nJH0wygLaHoLYX0a796Joe77m3vq4Cl79XuVIxaq/H+1ImzseVgrtfmtX8v3BXQ2rx7jpzGa/N3uNwFbD3kOpHupbnahSV14mxMnb3Z1HmrcM9na3DRy4u9HtsIqMdOF3rcoRgpOtyD7rJdR7HpwEl0nTwXHSbNAaB1xBoXktV7vY/yOXLqrON3KCopxeQfNuFwrusFJtDvMFgM8GF0YbvkoN+zZOJQNKwV7/W1v1yo9ewbbfXubbHGnQAANKuXgKUTh6JJHddRHlf0aI7GdXzPuB3m1i8QzcLVB3ilPlQzlCqaJTGvwHsn96u/aDXovUfzPZqKHvJyF2O4y5T6wpeb3l2Bl+dtd1mkfqo+n8Cbd37b45y/UMZ3tTvnNHbnnMKgFxZgoGmdBQCOuzT3AH/9O8tdOsQBbWKbcSEZ++ZSuNt/LB9pz/6CN/WlOrcczMWHSzNdZicDsKyDmQG+SnD+x9k6ZSQmjGyPq3ul4NZ+qQCAHi3ruex9x4BzvB6lWb0Ex11G3QStRp9QLRZv3+y9fb5lg0RUi+WfSLidtSA5WEWzJAZSw3Rvytjqo1nHlwVuk+6M/orTphFUtbwk9zPX8G98dzkAuORR8ubGd1dg6PRFfkdnGZPTikpKPWrcALAr5xT2uw1n/fdC17sfY0b4Z/rKbMb/P/cLplU1eI6DrwLMbaI1qsXir4Odna+zHxiANsm1HM/LGif83m1p+HT5XpQqbXRKQnysz5WrLmyXjIQA+w4qkyfHdHSMK6eq47Vfd6JrSj1c1LExvl/3hyMIPv6Ns8PUW1u1OZhvP+x5pxJI7pzth10vRifPFOEHvfmqqERh2HTPC+Sw6YswyO2u3LxGMuCc0GU0YRn/ld0vflal1Gb1rAroc04DAMDKJ4Z5vNapWd2glhbs0KQOnr2iC0bpE7X6tU5C+ya18fr1PTz2zS8sQXJt/wnTqsf5/hMa07UpvrirL1o0CG8HbyiGM1LwQjHD9c6P07H/WD4e/GKdY5t58p+3du6yZqfe/F7Zcx6Gv+LaVu/eeeurpr94u/+Lx51uHfDmFBnmZjN2skaxV8f1wLyHBqFRbe+zJMtjYNtkZE4bjbaNawMALvUybr5v6wZo17g2Pri9Nz7/8/mO7eYRQdekeXbC9mudhMxpo/HGDT3Rt3USfpsw1Gc57htyLmY/MKAiv4qHeD8XHbLOm3p66IpybxM3K6vpJVSsqFCfyC90WUvB3GxmVf+OZU00IvI+gDEAspVSna06T1Xzxg09AhoZY5YQH+sIxOFkjKAZ0l7raH352m4Y3qkJCotL8c2aLFzfpyVqVIvFp3r74qQxHTHlx82oWd3zjmJszxTMWuM5KelPA86Brwp3alJi0JkLXx3X3THFvDK7oE0Slu5ibvXK6isLJtA98d1GzF7vmfPHSlZWdT4EMNLC41dJY7o2Q4+W9cveMQIevridy3P3yShX9UxBrepxaFAzHncObI2a1eNcmkNa6aN5vN1uTr+2G36bMASrnrjIZXtCNWc+FPPppl7ZGZ/ccT4u7tg4qBQOV/RoHtTEn4ow0k0EyrxozNQru4S6OBRCRlbRUPK15oCVLAvwSqnFADyn81Gl9cCwttj2bPmvycZY+6Y+7lBaNEh0adN/5OJ2SIiPRVyM9meoFPDA0HPx6rjuuPH8VmjRIBHv3JKG2/t7HxXky+D2wQ1HfWVct6D2NzQPMneQeQSIOdkYRYe4CHznEW+sFJG7RCRdRNJzcrhSTKRVjyv/qJm01AZ444YemDS6Y9k7A7h/WFsAQIzpr/Dh4e1xRY/mLvsZNwm390/Fzqmjyjxuozo18NuEIS7bFvpYPnFoh0a4skcK/j76PK+vT7m8k6OT212Cn85tY+Uvs1qmNXoT4wNvHV3994vK3okqvbVesslaLeIBXin1tlIqTSmVlpwc/EQgCr3/3jcAP95fvo7PMV2bBT20Mi7G/5/hdb1b4vo+LfDgsLaIi41BhyZaf8SUyzv5fE91twyLZaVj7Z3qPYjf3C8VH9zW2+tr5zWtjdsuSPX6mreRTalJzjIEmroCAGp7SQdcWVQkIR5ZL+IBniqfLil10bl53bCdr6xRjQnxsXjuqq6ol6jN6H3q0k5o26gWLner6ZtHz5hryFOucO3jH9HJWbs2Uu0a7f9G4jhAWzgdAGpWj0PmtNGO58b+ybWrY/Jl3i8yDbykhmjRIBEN9XV6q8fF4Mu7+uKbv17geH3+Ixd6PZa3UUGt9QvWnPEDvb7HSqM6N8G4tBb4x5Vd8MkdfXBFd/tkLrUbTnSiiDDn0zc6c91n5PrSr00S5j18ocsMxlv6tcLkS53B1tx8cnPfVgCAuQ8NwtmiUnRJqYuZq/Zjwqz1jguB0THbpG4Nx1C8cb1bupx3XO+WeGyWNulmz3P+J5QZfQ11E6q5dNj9PH4gduWchojg/NZJLu9pWNP3nIPfHxuCAc87hw/+NH4gTuQXoXGdwIbOZjw1HHM3HcKMlfu8LjwTjDdv6uXy/P5hbfFdgEsEVsT7t6UFlKyNnKwcJjkDwGAADUUkC8BTSqn3rDofRc4Ht/f2mh7Xl61TRnpMRvp5/CA0qxfcOH8Rwbi0FhjdtanHjMLYGEF8XAzGX9TWsa2daajpoHbJSKgWi9v7pwKAY6TOdX1aYpJbBsRAtW1UC4nxscjIOonzmtbBq+O6o1er+i7jupNqVUdSLe+B3NvwUoN5aO3kSzuielwsGtfR9t8xdRRW7TmGG95dAQCoUyMOuQXFeP+2NAxqm4w4Pd3ENWktMGOla/KvcWktcKaoxDFrszxi3UZbPTisrWPtW3/uHdIGqzKPY2WAfzvnJju/v/jYGBRWIOd7tLAswCulrrfq2FS5DGnfyDFWPhDe2qfbNynfOP/nr+7q87Xtz/rukG1Stwa2THGOGKpfM96R5mHSdxuDSrL27BWd8ffvNqJD0zp47bru2PhHLrqkOJu4xvZMQRc/C69//Kc+SIyPRVxsDBLjY3Fd75YY3D4Zt7y/0tHfICKY8ee+uP6d5ejXpqHL+6vFxuCCc53bFvxtML5bdwBD2jfyGOrqPoDV+PwmjGyP33YccUkLECj3Reev79MSwzs1xrZDeXh4pu98/fGxsZj5l3547Ov1+DKABS/q13Q2e82463yMfdN7hstgdWhSO+i8OVUF2+CJ3Kx78mKPZgiDt9QM16Sl4Nq0FEwacx5ExCW4A9ocgNv8DPUc1C4ZaXon7+ZnRuLJSztiULtkbH5mBL6/z7lge7822gzhsi6GSbWq444B53hdVOPewd4XkUmpn4herbT5GS0bJOLru/u5XCDr+0g3DbiOggK0QNypWV1c1dM5y9m8wtidejK8q3pqfSjPX90Vix8dgimXd/LZ+bzx6RGoXaMabu7bCrWqx6FXqwYumVEXPzoESycO9ehv8cZ93Qb3UVvj0gJfh8GXOwac42gajCQGeCI39RLjfaY7WP74MCyZ6Jp6oXpcLF64ultIU0kAWkdxMMNWXx3XHY+P8j/56qKOjX3OdTAuB/FxMUhLbeDyGdSv6T1ltbunL+vktcyvXd8Db9yg5Tu69YJUZE4bjRamETgtkxJxc79UTBrjfYitMYdgyhWdsfHpEQCAR4ZrE/MGtm2IlkmJaFYvIaCgeq/bSmnuE/PaNq6FrikVG2Twf5ec59Kn5GsxoECG/VYEO1mJglC/Zjwq5zxkz5qoL9XjYvH5n8/3eUFyX2avVVIiXry6K8a+ucwxesd1f+1n83oJuNVt2Oil3Zphh56pcUzXZhjTNfARN6O7NMXsDQd9zmS+Jq0FmtdPQPcW9Vy2J9eujhx92cBHLm6HWy5IhQjww7oDuNTt/FOv7Iyjp7RO9f7nJmHJzqMY3D4Z/dokeeR+dy+XP7Exgit7NHc0UdXU70yGd2yMSWM64lBuAXLPFDn6R6zCGjxRFLqgTUOc26iWy7ZWSTXRs2U9PHeVs19j1j39MOueCxxDVL0xAry3Zfhev74H5owfFHC5jENcm5bimCz2mpdMp4YL2jT0mDS24nEt62q1WMH9w9qibkI11KlRDTf1bYW6elPTJ3f0cbzfqMH3atUAmdNG49xGtVHf7ff98HbnXIiGteJxaz/fdwr/vK679ruYPpDe+mS5gW0bokWDRPRObYBh52m/36JHB2PRo4N9Hq8iWIMnIgBa08w3f+3vsq1XKy0w1a4Rh3Mb1XIZimowcpm7d7aWx4hOTfDRsr24Z/C5OKdhTfQ/t2GZKavdxcQIlkwc6nemsZFNFXCW3zwaqFm9BNx4fkt8pi852KRuDdwzuA3eXLgLjerUQKukRHy0bC8A4KlLO7os81hc4rwDal4vAbkFRejUrC5+mzDEa6LBVkn+J+FVBAM8EZWpelwsfnnY+0SsJH1JyVB0KtavGY+fHnRO3go2uBuCydhqzCVwH6Y79couuL1/Kt5ZvAdtG9XGhBHt0b5xbYzp2hRbDmrNTk+O6eiR6te8aPpiU8qMFhGY9Svu7W2RlJaWptLTOZGBiMKntFRh/tZsXHSe57BSfzKPnEarpES88etOTJ+3HY3rVMfh3LP46u5+PlNfWEFEViulvK67yRo8EUW1mBjxmhyuLEZ+I2M91TsHtMbIzk0iUlP3hQGeiKgC/jyoNQqKSnBzv1ZBLZ8ZDgzwREQVUKt6HB6/xHu66UjjMEkiIptigCcisikGeCIim2KAJyKyKQZ4IiKbYoAnIrIpBngiIptigCcisqlKlYtGRHIA7C3n2xsCOBLC4oQKyxUclis4LFdw7FiuVkqpZG8vVKoAXxEiku4r4U4ksVzBYbmCw3IFJ9rKxSYaIiKbYoAnIrIpOwX4tyNdAB9YruCwXMFhuYITVeWyTRs8ERG5slMNnoiITBjgiYhsqsoHeBEZKSLbRGSniEwM87lbiMgCEdkiIptE5EF9+2QR+UNE1un/LjG953G9rNtEZISFZcsUkQ36+dP1bQ1EZJ6I7NB/1g9nuUSkvekzWSciuSIyPhKfl4i8LyLZIrLRtC3oz0dEeumf804ReU2CWdQz8HK9KCJbRWS9iHwrIvX07akicsb0ub1lVbn8lC3o7y5Mn9mXpjJlisg6fXtYPjM/sSG8f2NKqSr7D0AsgF0AWgOIB5ABoGMYz98UQE/9cW0A2wF0BDAZwN+87N9RL2N1AOfoZY+1qGyZABq6bXsBwET98UQAz4e7XG7f3SEArSLxeQEYBKAngI0V+XwArATQD4AA+AnAKAvKNRxAnP74eVO5Us37uR0npOXyU7agv7twfGZur08H8GQ4PzP4jg1h/Rur6jX4PgB2KqV2K6UKAXwB4PJwnVwpdVAptUZ/nAdgC4Dmft5yOYAvlFJnlVJ7AOyE9juEy+UAPtIffwTgigiWaxiAXUopfzOXLSuXUmoxgGNezhfw5yMiTQHUUUotU9r/xI9N7wlZuZRSc5VSxfrT5QBS/B3DinL5KpsfEf3MDHpt91oAM/wdI9Tl8hMbwvo3VtUDfHMA+03Ps+A/wFpGRFIB9ACwQt90n35L/b7pNiyc5VUA5orIahG5S9/WWCl1END+AAE0ikC5DNfB9T9dpD8vIPjPp7n+OFzlA4A/QavFGc4RkbUiskhEBurbwl2uYL67cJdtIIDDSqkdpm1h/czcYkNY/8aqeoD31hYV9nGfIlILwCwA45VSuQDeBNAGQHcAB6HdIgLhLW9/pVRPAKMA3Csig/zsG9bPUUTiAVwG4Ct9U2X4vPzxVY5wf25PACgG8Jm+6SCAlkqpHgAeBvC5iNQJc7mC/e7C/Z1eD9eKRFg/My+xweeuPs5foXJV9QCfBaCF6XkKgAPhLICIVIP2BX6mlPoGAJRSh5VSJUqpUgDvwNmsELbyKqUO6D+zAXyrl+Gwfstn3JJmh7tculEA1iilDutljPjnpQv288mCa3OJZeUTkVsBjAFwo36rDv12/qj+eDW0dtt24SxXOb67cH5mcQCuAvClqbxh+8y8xQaE+W+sqgf4VQDaisg5eq3wOgA/hOvkevveewC2KKVeNm1vatrtSgBG7/4PAK4Tkeoicg6AttA6UEJdrpoiUtt4DK2TbqN+/lv13W4F8H04y2XiUquK9OdlEtTno99i54lIX/1v4RbTe0JGREYCeAzAZUqpfNP2ZBGJ1R+31su1O1zl0s8b1HcXzrIBuAjAVqWUo4kjXJ+Zr9iAcP+NlbeXuLL8A3AJtB7qXQCeCPO5B0C7XVoPYJ3+7xIAnwDYoG//AUBT03ue0Mu6DSEY2eCjXK2h9chnANhkfC4AkgDMB7BD/9kgnOXSz5MI4CiAuqZtYf+8oF1gDgIoglZLuqM8nw+ANGhBbReAN6DPDg9xuXZCa581/sbe0vcdq3+/GQDWALjUqnL5KVvQ3104PjN9+4cA7nbbNyyfGXzHhrD+jTFVARGRTVX1JhoiIvKBAZ6IyKYY4ImIbIoBnojIphjgiYhsigGebENETuk/U0XkhhAf+//cni8N5fGJrMAAT3aUCiCoAG9MfvHDJcArpS4IskxEYccAT3Y0DcBAPd/3QyISK1pO9VV6Uqy/AICIDNZzdn8ObbIOROQ7PUHbJiNJm4hMA5CgH+8zfZtxtyD6sTeKlrN7nOnYC0Xka9FyuX+mz0SEiEwTkc16WV4K+6dDUSMu0gUgssBEaDnKxwCAHqhPKqV6i0h1AEtEZK6+bx8AnZWWohUA/qSUOiYiCQBWicgspdREEblPKdXdy7mugpZoqxuAhvp7Fuuv9QDQCVrukCUA+ovIZmhT+jsopZToi3cQWYE1eIoGwwHcItqqPiugTRdvq7+20hTcAeABEcmAlne9hWk/XwYAmKG0hFuHASwC0Nt07CylJeJaB63pKBdAAYB3ReQqAPmehyQKDQZ4igYC4H6lVHf93zlKKaMGf9qxk8hgaAmq+imlugFYC6BGAMf25azpcQm0VZmKod01zIK2cMOcIH4PoqAwwJMd5UFbJs3wM4B79PStEJF2epZNd3UBHFdK5YtIBwB9Ta8VGe93sxjAOL2dPxna8nE+M17q+cHrKqX+B2A8tOYdIkuwDZ7saD2AYr2p5UMA/4TWPLJG7+jMgfdlz+YAuFtE1kPL6Lfc9NrbANaLyBql1I2m7d9CWy8zA1r2wAlKqUP6BcKb2gC+F5Ea0Gr/D5XrNyQKALNJEhHZFJtoiIhsigGeiMimGOCJiGyKAZ6IyKYY4ImIbIoBnojIphjgiYhs6v8B+1mozFIBmQQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [6:19:14<00:00, 11.38s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Define optimizer and training operation ###\n",
    "\n",
    "'''TODO: instantiate a new model for training using the `build_model`\n",
    "  function and the hyperparameters created above.'''\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "'''TODO: instantiate an optimizer with its learning rate.\n",
    "  Checkout the tensorflow website for a list of supported optimizers.\n",
    "  https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/\n",
    "  Try using the Adam optimizer to start.'''\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y): \n",
    "  # Use tf.GradientTape()\n",
    "  with tf.GradientTape() as tape:\n",
    "  \n",
    "    '''TODO: feed the current input into the model and generate predictions'''\n",
    "    y_hat = model(x)\n",
    "  \n",
    "    '''TODO: compute the loss!'''\n",
    "    loss = compute_loss(y, y_hat)\n",
    "\n",
    "  # Now, compute the gradients \n",
    "  '''TODO: complete the function call for gradient computation. \n",
    "      Remember that we want the gradient of the loss with respect all \n",
    "      of the model parameters. \n",
    "      HINT: use `model.trainable_variables` to get a list of all model\n",
    "      parameters.'''\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  \n",
    "  # Apply the gradients to the optimizer so it can update the model accordingly\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "  return loss\n",
    "\n",
    "##################\n",
    "# Begin training!#\n",
    "##################\n",
    "\n",
    "history = []\n",
    "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "\n",
    "for iter in tqdm(range(num_training_iterations)):\n",
    "\n",
    "  # Grab a batch and propagate it through the network\n",
    "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
    "  loss = train_step(x_batch, y_batch)\n",
    "\n",
    "  # Update the progress bar\n",
    "  history.append(loss.numpy().mean())\n",
    "  plotter.plot(history)\n",
    "\n",
    "  # Update the model with the changed weights!\n",
    "  if iter % 100 == 0:     \n",
    "    model.save_weights(checkpoint_prefix)\n",
    "    \n",
    "# Save the trained model and the weights\n",
    "model.save_weights(checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## 2.6 Generate music using the RNN model\n",
    "\n",
    "Now, we can use our trained RNN model to generate some music! When generating music, we'll have to feed the model some sort of seed to get it started (because it can't predict anything without something to start with!).\n",
    "\n",
    "Once we have a generated seed, we can then iteratively predict each successive character (remember, we are using the ABC representation for our music) using our trained RNN. More specifically, recall that our RNN outputs a `softmax` over possible successive characters. For inference, we iteratively sample from these distributions, and then use our samples to encode a generated song in the ABC format.\n",
    "\n",
    "Then, all we have to do is write it to a file and listen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 음악을 만들기 위해 우리의 훈련된 RNN 모델을 사용할 수 있습니다! 음악을 만들어낼 때, 우리는 모델의 시작을 위해 몇 가지 시드를 공급해야 합니다. (왜냐하면 아무것도 없이 시작해서는 무엇도 예측할 수 없으니까요!) \n",
    "\n",
    "일단 우리가 생성된 시드를 가지고 나면, 우리는 훈련된 RNN을 사용하여 각각의 연속적인 문자를 반복적으로 예측할 수 있습니다(ABC 표기법의 음악을 사용한다는 걸 기억하세요). 보다 구체적으로 말하자면, 우리의 RNN은 가능한 연속적인 문자로 `softmax`를 출력한다는 것을 기억하세요. 추론(Inference)을 하는 동안, 이런 분포로부터 반복적으로 표본을 추출한 다음 생성된 노래를 ABC 표기법으로 인코딩하는 데 샘플을 사용합니다. \n",
    "\n",
    "자, 여러분들이 할 일은 파일로 작성하고 노래를 듣는 것만 남았습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIPcXllKjkdr"
   },
   "source": [
    "### Restore the latest checkpoint\n",
    "\n",
    "To keep this inference step simple, we will use a batch size of 1. Because of how the RNN state is passed from timestep to timestep, the model will only be able to accept a fixed batch size once it is built. \n",
    "\n",
    "To run the model with a different `batch_size`, we'll need to rebuild the model and restore the weights from the latest checkpoint, i.e., the weights after the last checkpoint during training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론(Inference) 단계를 간단하게 하기 위해서, batch 크기는 1로 사용할 겁니다. RNN의 state가 timestep에서 timestep으로 전달되는 방식 때문에, 모델은 오로지 한번 설정된 고정 batch 크기만을 수용할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (1, None, 256)            21248     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (1, None, 1024)           5246976   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, None, 83)             85075     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,353,299\n",
      "Trainable params: 5,353,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''TODO: Rebuild the model using a batch_size=1'''\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "# Restore the model weights for the last checkpoint after training\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9b4V2C8N62l"
   },
   "source": [
    "Notice that we have fed in a fixed `batch_size` of 1 for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론(Inference)를 위해 고정 batch 크기 1을 입력하였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "### The prediction procedure\n",
    "\n",
    "Now, we're ready to write the code to generate text in the ABC music format:\n",
    "\n",
    "* Initialize a \"seed\" start string and the RNN state, and set the number of characters we want to generate.\n",
    "\n",
    "* Use the start string and the RNN state to obtain the probability distribution over the next predicted character.\n",
    "\n",
    "* Sample from multinomial distribution to calculate the index of the predicted character. This predicted character is then used as the next input to the model.\n",
    "\n",
    "* At each time step, the updated RNN state is fed back into the model, so that it now has more context in making the next prediction. After predicting the next character, the updated RNN states are again fed back into the model, which is how it learns sequence dependencies in the data, as it gets more information from the previous predictions.\n",
    "\n",
    "![LSTM inference](https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_inference.png)\n",
    "\n",
    "Complete and experiment with this code block (as well as some of the aspects of network definition and training!), and see how the model performs. How do songs generated after training with a small number of epochs compare to those generated after a longer duration of training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 ABC 음악 형식으로 텍스트를 생성하기 위해 코드를 작성할 준비가 되었습니다. \n",
    "- \"시드\" 시작 문자열과 RNN state를 초기화 하고, 생성할 문자 수를 설정합니다.\n",
    "- 시작 문자열과 RNN state를 사용하여 다음 예측 문자에 대한 확률 분포를 얻습니다. \n",
    "- 예측 문자의 인덱스를 계산하기 위해 다항 분포 표본으로부터 샘플링합니다. 그런 다음 이 예측 문자를 모델의 다음 입력으로 사용합니다. \n",
    "- 각 time step에서, 업데이트 된 RNN state는 다시 모델에 공급되어, 다음 예측을 만들 때 더 많은 컨텍스트(context)를 갖게 됩니다. 다음 문자를 예측한 후, 업데이트 된 RNN states는 다시 모델에 공급되고, 이는 이전 예측으로부터 더 많은 정보를 얻기 때문에 데이터 속에서 시퀀스 종속성을 학습하게 하는 방법이 됩니다. \n",
    "\n",
    "![LSTM inference](https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_inference.png)\n",
    "\n",
    "코드 블록(신경망 정의 및 훈련의 일부분도 포함!)을 완성하고 실험하여 모델이 어떻게 동작하는지 확인해 봅시다. 짧은 epoch으로 훈련하여 만들어진 노래와 더 긴 epoch으로 훈련하여 만들어진 노래를 비교해 볼 때 어떻게 될 것 같나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "### Prediction of a generated song ###\n",
    "\n",
    "def generate_text(model, start_string, generation_length=1000):\n",
    "  # Evaluation step (generating ABC text using the learned RNN model)\n",
    "\n",
    "  '''TODO: convert the start string to numbers (vectorize)'''\n",
    "  #input_eval = [vectorize_string(start_string)]\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  tqdm._instances.clear()\n",
    "\n",
    "  for i in tqdm(range(generation_length)):\n",
    "      '''TODO: evaluate the inputs and generate the next character predictions'''\n",
    "      predictions = model(input_eval)\n",
    "      \n",
    "      # Remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "      \n",
    "      '''TODO: use a multinomial distribution to sample'''\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # Pass the prediction along with the previous hidden state\n",
    "      #   as the next inputs to the model\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "      '''TODO: add the predicted character to the generated text!'''\n",
    "      # Hint: consider what format the prediction is in vs. the output\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "    \n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ktovv0RFhrkn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 197.26it/s]\n"
     ]
    }
   ],
   "source": [
    "'''TODO: Use the model and the function defined above to generate ABC format text of length 1000!\n",
    "    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\n",
    "generated_text = generate_text(model, start_string=\"X\", generation_length=1000) # TODO\n",
    "# generated_text = generate_text('''TODO''', start_string=\"X\", generation_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM2Uma_-yVIq"
   },
   "source": [
    "### Play back the generated music!\n",
    "\n",
    "We can now call a function to convert the ABC format text to an audio file, and then play that back to check out our generated music! Try training longer if the resulting song is not long enough, or re-generating the song!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리는 ABC 형태의 텍스트를 오디오 파일로 변환하는 함수를 호출하여 생성한 음악을 확인하기 위해 실행할 수 있습니다! 만약 결과로 나온 노래가 충분히 길지 않다면 더 오래 훈련하거나 노래를 다시 만들어보세요! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "LrOtG64bfLto"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 songs in text\n"
     ]
    }
   ],
   "source": [
    "### Play back generated songs ###\n",
    "\n",
    "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
    "\n",
    "for i, song in enumerate(generated_songs): \n",
    "  # Synthesize the waveform from a song\n",
    "  waveform = mdl.lab1.play_song(song)\n",
    "\n",
    "  # If its a valid song (correct syntax), lets play it! \n",
    "  if waveform:\n",
    "    print(\"Generated song\", i)\n",
    "    ipythondisplay.display(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgVvcrYmSKGG"
   },
   "source": [
    "## 2.7 Experiment and **get awarded for the best songs**!\n",
    "\n",
    "Congrats on making your first sequence model in TensorFlow! It's a pretty big accomplishment, and hopefully you have some sweet tunes to show for it.\n",
    "\n",
    "Consider how you may improve your model and what seems to be most important in terms of performance. Here are some ideas to get you started:\n",
    "\n",
    "*  How does the number of training epochs affect the performance?\n",
    "*  What if you alter or augment the dataset? \n",
    "*  Does the choice of start string significantly affect the result? \n",
    "\n",
    "Try to optimize your model and submit your best song! **MIT students and affiliates will be eligible for prizes during the IAP offering**. To enter the competition, please [email us](mailto:introtodeeplearning-staff@mit.edu) with your name and the following:\n",
    "\n",
    "* a recording of your song;\n",
    "* Jupyter notebook with the code you used to generate the song;\n",
    "* a description and/or diagram of the architecture and hyperparameters you used -- if there are any additional or interesting modifications you made to the template code, please include these in your description.\n",
    "\n",
    "You can also tweet us at [@MITDeepLearning](https://twitter.com/MITDeepLearning) a copy of the song! See this example song generated by a previous 6.S191 student (credit Ana Heart): <a href=\"https://twitter.com/AnaWhatever16/status/1263092914680410112?s=20\">song from May 20, 2020.</a>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "Have fun and happy listening!\n",
    "\n",
    "![Let's Dance!](http://33.media.tumblr.com/3d223954ad0a77f4e98a7b87136aa395/tumblr_nlct5lFVbF1qhu7oio1_500.gif)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "uoJsVjtCMunI"
   ],
   "name": "Part2_Music_Generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
