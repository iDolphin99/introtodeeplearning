{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsvlBQYCrE4I"
   },
   "source": [
    "## 1. Dependencies\n",
    "\n",
    "cousre 저장소 다운로드, 실습 관련 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "riVZCVK65QTH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mitdeeplearning in c:\\users\\hyeongbin\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: regex in c:\\users\\hyeongbin\\anaconda3\\lib\\site-packages (from mitdeeplearning) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hyeongbin\\anaconda3\\lib\\site-packages (from mitdeeplearning) (4.62.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\hyeongbin\\appdata\\roaming\\python\\python38\\site-packages (from mitdeeplearning) (1.19.5)\n",
      "Requirement already satisfied: gym in c:\\users\\hyeongbin\\anaconda3\\lib\\site-packages (from mitdeeplearning) (0.21.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hyeongbin\\anaconda3\\lib\\site-packages (from gym->mitdeeplearning) (2.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hyeongbin\\anaconda3\\lib\\site-packages (from tqdm->mitdeeplearning) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\hyeongbin\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\hyeongbin\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\hyeongbin\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\hyeongbin\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\hyeongbin\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\hyeongbin\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "지정된 경로를 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# Import Tensorflow 2.0\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf \n",
    "\n",
    "# Download and import the MIT 6.S191 package\n",
    "!pip install mitdeeplearning\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "# Import all remaining packages\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
    "\n",
    "# Import\n",
    "import random\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "#assert len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ajvp0No4qDm"
   },
   "source": [
    "## 2. Dataset\n",
    "\n",
    "817 songs, 200,679 vectorized songs\n",
    "\n",
    "- ABC notation으로 표현된 수천 개의 아일랜드 민요(Irish folk songs) 데이터 \n",
    "- 단순히 연주되는 음에 대한 정보만이 아니라 추가적으로 노래 제목, 키, 템포와 같은 메타 정보도 포함함 \n",
    "- **텍스트 파일에 존재하는 다양한 문자들이 complexity of the learning problem에 어떤 영향을 미칠까?**\n",
    "- 위 문제는 텍스트 데이터를 수치 데이터로 만들때 중요해짐 : Preprocessing\n",
    "- 음악데이터만 사용하려면 어떻게 해야 할까요? \n",
    "- NLP 적인 처리가 필요하지 않을까? \n",
    "    - X : number\n",
    "    - T : title, 제목\n",
    "    - Z : ?? 음자리표인감 높은음자리표 이런거.. \n",
    "    - M : 뭐지? 첫 시작음? \n",
    "    - L : 박자표인듯\n",
    "    - K : key, 음계, 다장조 이런거 \n",
    "    - z : 악보, 우리가 실제로 훈련해야 할 것, 여기서 | 이거는 마디, !는 뭔지 모르겠음 :| 도돌이표\n",
    "- **songs** : 817개의 노래가 들어있는 list\n",
    "- **show_music_detail(num)** : num 개의 음악을 자세하게 볼 수 있습니다 \n",
    "- **mdl.lab1.play_song(example_song)** : text형 음악을(ABC notation) audio 파형으로 표현합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 817 songs in text\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "# colab으로 실행한다면 주석과 같이 작성할 것 \n",
    "# jupyter notebook으로 실행한다면 아래와 같이 작성할 것 \n",
    "# import pattern과 관련해서 수정해주어야 오류가 해결되는 것 같습니다\n",
    "\n",
    "from mitdeeplearning import lab1\n",
    "#songs = mdl.lab1.load_training_data()\n",
    "songs = lab1.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example song # 716 :\n",
      "X:384\n",
      "T:Woman of the House\n",
      "Z: id:dc-reel-355\n",
      "M:C\n",
      "L:1/8\n",
      "K:G Major\n",
      "E|DBBA B3A|GBB2 eBdB|A2GB A2Bd|eBB2 gfed|!\n",
      "DBBA B3A|GBB2 eBdB|GABG A2GA|BGAG EFG:|!\n",
      "e|f3d eBB2|eBgB eBB2|f3d edBd|eaa^g aba=g|!\n",
      "f3d eBB2|g3e dBB2|GABG A2GA|BGAG EFG:|!\n"
     ]
    }
   ],
   "source": [
    "# Print one of the songs to instpect it in greater detail! \n",
    "# my function -> Print N of the song... \n",
    "def show_music_detail(songs, num) :\n",
    "    num_list = sample(range(0, len(songs)), num) #sample output format is list\n",
    "    for i in num_list :\n",
    "        example_song = songs[i]\n",
    "        print(\"\\nExample song #\", i, \":\")\n",
    "        print(example_song)\n",
    "    \n",
    "show_music_detail(songs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_song = songs[random.randint(0, len(songs))]\n",
    "mdl.lab1.play_song(example_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## 3. Preprocessing\n",
    "\n",
    "1. Vectorize the text \n",
    "2. Make input sequence chunk from input text (and target sequence)\n",
    "\n",
    "- Prediction task :RNN 모델이 ABC notation 음악에서 패턴을 학습하도록 훈련할 것이며, 학습한 정보를 바탕으로 새로운 음악 생성(또는 예측)\n",
    "- 즉, 모델에게 정말로 요구하는 것은 문자, 문자들의 시퀀스, 다음 문자로 올 가장 가능성 높은 문자는 무엇인가? \n",
    "- input : 문자열 시퀀스 -> model -> output : 각 time step 에서 다음 문자를 예측하는 것 \n",
    "\n",
    "### Vectorize the text\n",
    "\n",
    "- 텍스트(text) 데이터셋 -> 수치(numerical) 데이터셋 => Vectorize \n",
    "    - **vocab**     : ABC notation에 있는 unique vocabulary(or character) \n",
    "    - **char2idx** : 문자 -> 숫자 mapping, 정수  \n",
    "    - **idx2char** : 숫자 -> 문자 mapping \n",
    "    - **vectorized_songs** : ABC notation 노래 text에서 벡터화된 노래 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "id": "IalZLbvOzf-F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 unique characters in the dataset\n",
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '#' :   4,\n",
      "  \"'\" :   5,\n",
      "  '(' :   6,\n",
      "  ')' :   7,\n",
      "  ',' :   8,\n",
      "  '-' :   9,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Join our list of song strings into a single string containing all songs\n",
    "# 노래 문자열(string) 목록을 이 모든 노래가 포함된 하나의 단일 문자열로 결합함\n",
    "songs_joined = \"\\n\\n\".join(songs) \n",
    "\n",
    "# Find all unique characters in the joined string\n",
    "# 결합된 노래 묶음 문자열에서 유일한(unique) 단어들을 모두 확인\n",
    "# 데이터셋에는 총 83개의 유일한 문자들이 존재함\n",
    "vocab = sorted(set(songs_joined))\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")\n",
    "\n",
    "\n",
    "### Define numerical representation of text ###  \n",
    "# 문자 -> unique index로 매핑\n",
    "# 예를 들어, \"d\"라는 문자의 인덱스는 char2idx[\"d\"]와 같이 작성하여 얻을 것임 \n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "\n",
    "# index -> 문자로 매핑 \n",
    "# char2idx의 반대 버전이며 index에서 다시 문자로 되돌리는 역할을 할 것임\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# [python] difference between str() and repr() \n",
    "# 숫자를 문자열로 변환시켜주는 함수임은 동일합니다. 하지만 기저에 작동하는 원리가 다른 것 같습니다. \n",
    "print('{')\n",
    "for char,_ in zip(char2idx, range(10)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "g-LnKyu4dczc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200679\n",
      "\n",
      "\"X:1\\nT:Alexander's\\nZ:\" \n",
      "---- characters mapped to int ---->\n",
      " [49 22 13  0 45 22 26 67 60 79 56 69 59 60 73  5 74  0 51 22]\n"
     ]
    }
   ],
   "source": [
    "### Vectorize the songs string ###\n",
    "# 문자열 벡터화 함수, return은 무조건 'N(입력 문자열의 문자 개수)'요소의 np.array\n",
    "def vectorize_string(string):\n",
    "    # TODO\n",
    "    vectorized_list = []\n",
    "    vectorized_list = ([char2idx[_] for _ in string])\n",
    "    return np.array(vectorized_list)\n",
    "\n",
    "# my function -> Print N length of vectorized songs \n",
    "# 나중에 곡 하나를 통째로 vectorized 한 결과를 두 개 (원곡, vectorized) 보여주는 함수도 짜면 좋을 것 같음 \n",
    "def show_music_vectorized(vectorized_songs, length) :\n",
    "    print ('\\n{} \\n---- characters mapped to int ---->\\n {}'.format(repr(songs_joined[:length]), vectorized_songs[:length]))\n",
    "\n",
    "vectorized_songs = vectorize_string(songs_joined)\n",
    "print(len(vectorized_songs)) # 200,679\n",
    "show_music_vectorized(vectorized_songs, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X:1\\nT:Alexander's\\nZ: id:dc-hornpipe-1\\nM:C|\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X:2\\nT:An Buachaill Dreoite\\nZ: id:dc-hornpipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X:3\\nT:Belfast\\nZ: id:dc-hornpipe-3\\nM:C|\\nL:1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X:4\\nT:Blackbird\\nZ: id:dc-hornpipe-4\\nM:C|\\nL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X:5\\nT:Bobby Casey's\\nZ: id:dc-hornpipe-5\\nM:C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               songs\n",
       "0  X:1\\nT:Alexander's\\nZ: id:dc-hornpipe-1\\nM:C|\\...\n",
       "1  X:2\\nT:An Buachaill Dreoite\\nZ: id:dc-hornpipe...\n",
       "2  X:3\\nT:Belfast\\nZ: id:dc-hornpipe-3\\nM:C|\\nL:1...\n",
       "3  X:4\\nT:Blackbird\\nZ: id:dc-hornpipe-4\\nM:C|\\nL...\n",
       "4  X:5\\nT:Bobby Casey's\\nZ: id:dc-hornpipe-5\\nM:C..."
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.DataFrame(songs, columns = [\"songs\"])\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "      <th>X</th>\n",
       "      <th>T</th>\n",
       "      <th>Z</th>\n",
       "      <th>M</th>\n",
       "      <th>L</th>\n",
       "      <th>K</th>\n",
       "      <th>score</th>\n",
       "      <th>vectorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X:1\\nT:Alexander's\\nZ: id:dc-hornpipe-1\\nM:C|\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>Alexander's</td>\n",
       "      <td>id:dc-hornpipe-1</td>\n",
       "      <td>C|</td>\n",
       "      <td>1/8</td>\n",
       "      <td>D Major</td>\n",
       "      <td>(3ABc|dAFA DFAd|fdcd FAdf|gfge fefd|(3efe (3dc...</td>\n",
       "      <td>[6, 15, 26, 27, 58, 82, 59, 26, 31, 26, 1, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X:2\\nT:An Buachaill Dreoite\\nZ: id:dc-hornpipe...</td>\n",
       "      <td>2</td>\n",
       "      <td>An Buachaill Dreoite</td>\n",
       "      <td>id:dc-hornpipe-2</td>\n",
       "      <td>C|</td>\n",
       "      <td>1/8</td>\n",
       "      <td>G Major</td>\n",
       "      <td>GF|DGGB d2GB|d2GF Gc (3AGF|DGGB d2GB|dBcA F2GF|!</td>\n",
       "      <td>[32, 31, 82, 29, 32, 32, 27, 1, 59, 14, 32, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X:3\\nT:Belfast\\nZ: id:dc-hornpipe-3\\nM:C|\\nL:1...</td>\n",
       "      <td>3</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>id:dc-hornpipe-3</td>\n",
       "      <td>C|</td>\n",
       "      <td>1/8</td>\n",
       "      <td>D Major</td>\n",
       "      <td>ag|(3faf df AdFA|DFAd f2ef|gbec dfAF|GABG E2ag|!</td>\n",
       "      <td>[56, 62, 82, 6, 15, 61, 56, 61, 1, 59, 61, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X:4\\nT:Blackbird\\nZ: id:dc-hornpipe-4\\nM:C|\\nL...</td>\n",
       "      <td>4</td>\n",
       "      <td>Blackbird</td>\n",
       "      <td>id:dc-hornpipe-4</td>\n",
       "      <td>C|</td>\n",
       "      <td>1/8</td>\n",
       "      <td>D Mixolydian</td>\n",
       "      <td>AG|F2FA GFD2|de (3fed d^cAF|G2GF GFDE|FdcA G2AG|!</td>\n",
       "      <td>[26, 32, 82, 31, 14, 31, 26, 1, 32, 31, 29, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X:5\\nT:Bobby Casey's\\nZ: id:dc-hornpipe-5\\nM:C...</td>\n",
       "      <td>5</td>\n",
       "      <td>Bobby Casey's</td>\n",
       "      <td>id:dc-hornpipe-5</td>\n",
       "      <td>C|</td>\n",
       "      <td>1/8</td>\n",
       "      <td>A Dorian</td>\n",
       "      <td>ed|cAAB cBcd|eaaf gedB|c2Ac B2Bc|d2de dBGB|!</td>\n",
       "      <td>[60, 59, 82, 58, 26, 26, 27, 1, 58, 27, 58, 59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>X:6\\nT:Inisheer\\nZ: id:dc-waltz-4\\nM:3/4\\nL:1/...</td>\n",
       "      <td>6</td>\n",
       "      <td>Inisheer</td>\n",
       "      <td>id:dc-waltz-4</td>\n",
       "      <td>3/4</td>\n",
       "      <td>1/8</td>\n",
       "      <td>G Major</td>\n",
       "      <td>D2|B3 A Bd|B3 A Bd|E3 B AB|D3 E GA|!</td>\n",
       "      <td>[29, 14, 82, 27, 15, 1, 26, 1, 27, 59, 82, 27,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>X:7\\nT:Mrs. Kenny's\\nZ: id:dc-waltz-7\\nM:3/4\\n...</td>\n",
       "      <td>7</td>\n",
       "      <td>Mrs. Kenny's</td>\n",
       "      <td>id:dc-waltz-7</td>\n",
       "      <td>3/4</td>\n",
       "      <td>1/8</td>\n",
       "      <td>D Major</td>\n",
       "      <td>A2|f2 fe dc|d4 FG|A2 G3B,|A,2 C2 E2|!</td>\n",
       "      <td>[26, 14, 82, 61, 14, 1, 61, 60, 1, 59, 58, 82,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>X:8\\nT:South Wind\\nZ: id:dc-waltz-5\\nM:3/4\\nL:...</td>\n",
       "      <td>8</td>\n",
       "      <td>South Wind</td>\n",
       "      <td>id:dc-waltz-5</td>\n",
       "      <td>3/4</td>\n",
       "      <td>1/8</td>\n",
       "      <td>G Major</td>\n",
       "      <td>c2|B3 A G2|B3 c d2|A6|A4 c2|B3 A G2|E3 D E2|G6...</td>\n",
       "      <td>[58, 14, 82, 27, 15, 1, 26, 1, 32, 14, 82, 27,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>X:9\\nT:Spinning Wheel\\nZ: id:dc-waltz-11\\nM:3/...</td>\n",
       "      <td>9</td>\n",
       "      <td>Spinning Wheel</td>\n",
       "      <td>id:dc-waltz-11</td>\n",
       "      <td>3/4</td>\n",
       "      <td>1/8</td>\n",
       "      <td>G Major</td>\n",
       "      <td>D|G2 B3 D|G2 B2 D2|G2 B2 d2|d2 c2 AG|F2 A2 D2|...</td>\n",
       "      <td>[29, 82, 32, 14, 1, 27, 15, 1, 29, 82, 32, 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>X:10\\nT:Tommy Bhetty's\\nZ: id:dc-waltz-6\\nM:3/...</td>\n",
       "      <td>10</td>\n",
       "      <td>Tommy Bhetty's</td>\n",
       "      <td>id:dc-waltz-6</td>\n",
       "      <td>3/4</td>\n",
       "      <td>1/8</td>\n",
       "      <td>G Major</td>\n",
       "      <td>z D2|G3 B dB|G3 B dB|d2 b3 a|ga fg ef|!</td>\n",
       "      <td>[81, 1, 29, 14, 82, 32, 15, 1, 27, 1, 59, 27, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>817 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 songs   X  \\\n",
       "0    X:1\\nT:Alexander's\\nZ: id:dc-hornpipe-1\\nM:C|\\...   1   \n",
       "1    X:2\\nT:An Buachaill Dreoite\\nZ: id:dc-hornpipe...   2   \n",
       "2    X:3\\nT:Belfast\\nZ: id:dc-hornpipe-3\\nM:C|\\nL:1...   3   \n",
       "3    X:4\\nT:Blackbird\\nZ: id:dc-hornpipe-4\\nM:C|\\nL...   4   \n",
       "4    X:5\\nT:Bobby Casey's\\nZ: id:dc-hornpipe-5\\nM:C...   5   \n",
       "..                                                 ...  ..   \n",
       "812  X:6\\nT:Inisheer\\nZ: id:dc-waltz-4\\nM:3/4\\nL:1/...   6   \n",
       "813  X:7\\nT:Mrs. Kenny's\\nZ: id:dc-waltz-7\\nM:3/4\\n...   7   \n",
       "814  X:8\\nT:South Wind\\nZ: id:dc-waltz-5\\nM:3/4\\nL:...   8   \n",
       "815  X:9\\nT:Spinning Wheel\\nZ: id:dc-waltz-11\\nM:3/...   9   \n",
       "816  X:10\\nT:Tommy Bhetty's\\nZ: id:dc-waltz-6\\nM:3/...  10   \n",
       "\n",
       "                        T                  Z    M    L             K  \\\n",
       "0             Alexander's   id:dc-hornpipe-1   C|  1/8       D Major   \n",
       "1    An Buachaill Dreoite   id:dc-hornpipe-2   C|  1/8       G Major   \n",
       "2                 Belfast   id:dc-hornpipe-3   C|  1/8       D Major   \n",
       "3               Blackbird   id:dc-hornpipe-4   C|  1/8  D Mixolydian   \n",
       "4           Bobby Casey's   id:dc-hornpipe-5   C|  1/8      A Dorian   \n",
       "..                    ...                ...  ...  ...           ...   \n",
       "812              Inisheer      id:dc-waltz-4  3/4  1/8       G Major   \n",
       "813          Mrs. Kenny's      id:dc-waltz-7  3/4  1/8       D Major   \n",
       "814            South Wind      id:dc-waltz-5  3/4  1/8       G Major   \n",
       "815        Spinning Wheel     id:dc-waltz-11  3/4  1/8       G Major   \n",
       "816        Tommy Bhetty's      id:dc-waltz-6  3/4  1/8       G Major   \n",
       "\n",
       "                                                 score  \\\n",
       "0    (3ABc|dAFA DFAd|fdcd FAdf|gfge fefd|(3efe (3dc...   \n",
       "1     GF|DGGB d2GB|d2GF Gc (3AGF|DGGB d2GB|dBcA F2GF|!   \n",
       "2     ag|(3faf df AdFA|DFAd f2ef|gbec dfAF|GABG E2ag|!   \n",
       "3    AG|F2FA GFD2|de (3fed d^cAF|G2GF GFDE|FdcA G2AG|!   \n",
       "4         ed|cAAB cBcd|eaaf gedB|c2Ac B2Bc|d2de dBGB|!   \n",
       "..                                                 ...   \n",
       "812               D2|B3 A Bd|B3 A Bd|E3 B AB|D3 E GA|!   \n",
       "813              A2|f2 fe dc|d4 FG|A2 G3B,|A,2 C2 E2|!   \n",
       "814  c2|B3 A G2|B3 c d2|A6|A4 c2|B3 A G2|E3 D E2|G6...   \n",
       "815  D|G2 B3 D|G2 B2 D2|G2 B2 d2|d2 c2 AG|F2 A2 D2|...   \n",
       "816            z D2|G3 B dB|G3 B dB|d2 b3 a|ga fg ef|!   \n",
       "\n",
       "                                            vectorized  \n",
       "0    [6, 15, 26, 27, 58, 82, 59, 26, 31, 26, 1, 29,...  \n",
       "1    [32, 31, 82, 29, 32, 32, 27, 1, 59, 14, 32, 27...  \n",
       "2    [56, 62, 82, 6, 15, 61, 56, 61, 1, 59, 61, 1, ...  \n",
       "3    [26, 32, 82, 31, 14, 31, 26, 1, 32, 31, 29, 14...  \n",
       "4    [60, 59, 82, 58, 26, 26, 27, 1, 58, 27, 58, 59...  \n",
       "..                                                 ...  \n",
       "812  [29, 14, 82, 27, 15, 1, 26, 1, 27, 59, 82, 27,...  \n",
       "813  [26, 14, 82, 61, 14, 1, 61, 60, 1, 59, 58, 82,...  \n",
       "814  [58, 14, 82, 27, 15, 1, 26, 1, 32, 14, 82, 27,...  \n",
       "815  [29, 82, 32, 14, 1, 27, 15, 1, 29, 82, 32, 14,...  \n",
       "816  [81, 1, 29, 14, 82, 32, 15, 1, 27, 1, 59, 27, ...  \n",
       "\n",
       "[817 rows x 9 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split \n",
    "input_data[['X', 'temp']] = input_data['songs'].str.split(\"\\nT:\", expand=True)\n",
    "input_data['T'] = input_data['temp'].str.split(\"\\nZ:\").str[0]\n",
    "input_data['temp'] = input_data['temp'].str.split(\"\\nZ:\").str[1]\n",
    "input_data['Z'] = input_data['temp'].str.split(\"\\nM:\").str[0]\n",
    "input_data['temp'] = input_data['temp'].str.split(\"\\nM:\").str[1]\n",
    "input_data['M'] = input_data['temp'].str.split(\"\\nL:\").str[0]\n",
    "input_data['temp'] = input_data['temp'].str.split(\"\\nL:\").str[1]\n",
    "input_data['L'] = input_data['temp'].str.split(\"\\nK:\").str[0]\n",
    "input_data['temp'] = input_data['temp'].str.split(\"\\nK:\").str[1]\n",
    "input_data['K'] = input_data['temp'].str.split(\"\\n\").str[0]\n",
    "input_data['score'] = input_data['temp'].str.split(\"\\n\").str[1]\n",
    "\n",
    "# drop and applying \n",
    "input_data['X'] = input_data['X'].str.split(\"X:\").str[1]\n",
    "input_data = input_data.drop(columns = ['temp'])\n",
    "input_data[\"score\"] = input_data[\"score\"].apply(str)\n",
    "\n",
    "# vectorized string \n",
    "input_data[\"vectorized\"] = \"\"\n",
    "for i in range (0, 817) : \n",
    "    input_data[\"vectorized\"][i] = vectorize_string(input_data[\"score\"][i])\n",
    "    \n",
    "    \n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G Major         249\n",
       "D Major         229\n",
       "A Dorian         81\n",
       "D Mixolydian     61\n",
       "E Dorian         49\n",
       "A Major          36\n",
       "E Minor          23\n",
       "A Mixolydian     21\n",
       "D Dorian         12\n",
       "D Minor           9\n",
       "F Major           9\n",
       "B Minor           8\n",
       "C Major           7\n",
       "G Dorian          6\n",
       "G Mixolydian      5\n",
       "B Dorian          5\n",
       "E Major           3\n",
       "F# Minor          1\n",
       "A Minor           1\n",
       "Name: K, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[\"K\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      12\n",
       "3      11\n",
       "9      11\n",
       "1      10\n",
       "4      10\n",
       "       ..\n",
       "249     1\n",
       "250     1\n",
       "251     1\n",
       "252     1\n",
       "386     1\n",
       "Name: X, Length: 386, dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[\"X\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Create training examples and targets\n",
    "\n",
    "- 실제 텍스트를 훈련 중에 사용할 예제 시퀀스로 나눌 것\n",
    "- 입력 텍스트를 seq_length 단위로 나눔\n",
    "- 예를 들어 텍스트는 Hello 이고 seq_length가 4라면 hell가 input, elloo가 target이 됨 \n",
    "- 이로부터 batch 방법을 사용하여 해당 문자 인덱스 스트림을 원하는 크기의 시퀀스로 변환 가능 \n",
    "- 각각의 벡터,각각의 index는 하나의 단일 time step으로 처리 \n",
    "- 즉, time step 0 은 들어온 시퀀스의 첫 번째 문자에 대한 인덱스를 받고 그 다음 인덱스 1의 문자를 맞출 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LF-N8F7BoDRi"
   },
   "outputs": [],
   "source": [
    "### Batch definition to create training examples ###\n",
    "def get_batch(vectorized_songs, seq_length, batch_size):\n",
    "    # the length of the vectorized songs string\n",
    "    n = vectorized_songs.shape[0] - 1 # 200679 - 1 = 200678 \n",
    "    # randomly choose the starting indices for the examples in the training batch\n",
    "    # 0 ~ 200678-seq_length 숫자 사이에서 batch_size개의 임의의 표본 추출 -> 즉 batch size가 n개면 idx도 n개 나옴\n",
    "    idx = np.random.choice(n-seq_length, batch_size) \n",
    "    print(\"idx: \", idx) \n",
    "    \n",
    "    '''TODO: construct a list of input sequences for the training batch'''\n",
    "    input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
    "    print(\"input batch: \", len(input_batch)) # batch size 는 seq_length 값과 동일, 그래서 step의 수도 0~seq_length-1 까지임! \n",
    "    '''TODO: construct a list of output sequences for the training batch'''\n",
    "    output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
    "    print(\"output batch: \", len(output_batch))\n",
    "    \n",
    "    # x_batch, y_batch provide the true inputs and targets for network training\n",
    "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "    y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0eBu9WZG84i0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  [102226]\n",
      "input batch:  1\n",
      "output batch:  1\n",
      "Step   0\n",
      "  input: 27 ('B')\n",
      "  expected output: 1 (' ')\n",
      "Step   1\n",
      "  input: 1 (' ')\n",
      "  expected output: 26 ('A')\n",
      "Step   2\n",
      "  input: 26 ('A')\n",
      "  expected output: 31 ('F')\n",
      "Step   3\n",
      "  input: 31 ('F')\n",
      "  expected output: 30 ('E')\n",
      "Step   4\n",
      "  input: 30 ('E')\n",
      "  expected output: 26 ('A')\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
    "\n",
    "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
    "    print(\"Step {:3d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def graph(pred) :\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(pred, label = 'actual')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "graph(vectorized_songs.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## 2.4 The Recurrent Neural Network (RNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    " 모델은 LSTM 구조를 기반하는데, 이 구조는 연속되는 문자들 사이의 시간 관계(temporal relationships)에 대한 정보를 유지하는 state 벡터를 사용합니다. LSTM의 최종 출력은 fully-connected `Dense` layer로 넘겨지는데, 여기서 vocabulary의 각 문자에 대해 softmax를 계산하고(출력하고) 이로부터 만들어진 불포에서 샘플을 추춘하여 다음 문자를 예측합니다. \n",
    "\n",
    "* keras API [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential)를 사용합니다. 모델을 정의하기 위해 세 개의 레이어가 사용됩니다. \n",
    "* [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) : 입력 레이어, 각 문자의 숫자들을 `embedding_dim`차원의 벡터로 매핑하는 훈련 가능한 lookup 테이블로 구성됨 \n",
    "* [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): `units=rnn_units` 크기의 LSTM 신경망\n",
    "* [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): `vocab_size` 출력이 있는 출력 레이어\n",
    "* `Model.summary` : 모델의 내부 작동에 대한 summary를 출력, 모델 내부의 레이어, 각 레이어의 출력 형태(shape), 배치 사이즈 등을 확인해 볼 수 있습니다.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8DsWzojvkbc7"
   },
   "outputs": [],
   "source": [
    "# define model function \n",
    "def LSTM(rnn_units): \n",
    "    return tf.keras.layers.LSTM(\n",
    "        rnn_units, \n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        recurrent_activation='sigmoid',\n",
    "        stateful=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "### Defining the RNN Model ###\n",
    "'''TODO: Add LSTM and Dense layers to define the RNN model using the Sequential API.'''\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        # Layer 1: Embedding layer to transform indices into dense vectors of a fixed embedding size\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "\n",
    "        # Layer 2: LSTM with `rnn_units` number of units. \n",
    "        # TODO: Call the LSTM function defined above to add this layer.\n",
    "        LSTM(rnn_units),\n",
    "\n",
    "        # Layer 3: Dense (fully-connected) layer that transforms the LSTM output into the vocabulary size. \n",
    "        # TODO: Add the Dense layer.\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "    return model\n",
    "\n",
    "# Build a simple model with default hyperparameters. You will get the chance to change these later.\n",
    "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RwG1DD6rDrRM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, None, 256)           21248     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (32, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, None, 83)            85075     \n",
      "=================================================================\n",
      "Total params: 5,353,299\n",
      "Trainable params: 5,353,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "### Test out the RNN model\n",
    "\n",
    "모델의 예상 작동을 확인하기 위한 간단한 테스트 시행합니다. 길이 100의 시퀀스를 사용하여 출력물의 차원도 확인해보자. \n",
    "**모델에는 어떤 길이의 입력도 동작할 수 있음을 주의!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  [120859  50113  65618  57080  83245 174192  92495 175885  63312  77416\n",
      "  61254  92585  11071 129007  85290 196486 177923 179188 182693  97211\n",
      "  64206  81520 195326  92560  77703 150613 191106   2144  27006 122422\n",
      "  65328 112407]\n",
      "input batch:  32\n",
      "output batch:  32\n",
      "Input shape:       (32, 100)  # (batch_size, sequence_length)\n",
      "Prediction shape:  (32, 100, 83) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
    "pred = model(x)\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT1HvFVUGpoE"
   },
   "source": [
    "### Predictions from the untrained model\n",
    "\n",
    "훈련시키지 않은 모델의 예측은 어떨까? \n",
    "\n",
    "모델의 실제 예측을 얻기 위해서, 우리는 문자 vocabulary를 `softmax`로 정의한 출력 분포에서 샘플을 추출해야 합니다. 이는 우리에게 실제 문자 인덱스틀 제공합니다. 즉, 범주형 분포([categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) )을 사용하여 예제 예측을 샘플로 추출함을 의미합니다. 이로써 각 time step에서 다음 문자(특히나 그 인덱스에서의)에 대한 예측을 하게 됩니다. \n",
    "\n",
    "여기서는 단순히 `argmax`를 취하는 대신 확률 분포에서 표본을 추출합니다. (그리고 argmax는 모델이 루프에 빠지게 만들 수 있습니다?)\n",
    "\n",
    "첫 번째 예시 batch에서 샘플링을 실행해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55, 51, 60, 16, 81, 73, 26,  0, 39, 51, 82, 24, 26, 62, 38, 42,  7,\n",
       "       80, 40, 71, 63, 26, 80,  1, 76, 41, 17, 18, 48, 45,  6, 33, 19, 53,\n",
       "       77, 65, 70, 18, 14, 58, 70, 14, 32, 82, 75, 46, 73,  2, 19, 38, 52,\n",
       "       10, 80, 35, 30,  4,  1, 17,  4, 59, 34, 77,  8, 69, 10, 76, 67, 66,\n",
       "       16, 79, 79,  2, 43, 59, 42, 77, 34, 46, 49,  0, 24, 31,  0, 23, 82,\n",
       "       64, 33, 30, 46, 27, 80, 45, 12, 78, 63, 31, 58, 80,  2,  3],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이들을 디코딩하여 훈련되지 않은 모델이 예측한 텍스트를 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'D2:|!\\n\\nX:160\\nT:Jenny Rocking the Cradle\\nZ: id:dc-reel-147\\nM:C\\nL:1/8\\nK:D Major\\nFE|DFFd AFFA|DFFd ABAF'\n",
      "\n",
      "Next Char Predictions: \n",
      " '_Ze4zrA\\nNZ|=AgMQ)yOphAy uP56WT(H7]vjo62co2G|tUr!7M[.yJE# 5#dIv,n.ulk4xx!RdQvIUX\\n=F\\n<|iHEUByT0whFcy!\"'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## 2.5 Training the model: loss and training operations\n",
    "\n",
    "다음 문자를 예측하는 문제를 일반적으로 분류 문제(classification, 여기서는 이진 분류가 아닌 multi-class)로 생각해 볼 수 있습니다. \n",
    "RNN의 이전 state와 주어진 time step에서의 입력을 고려하여 다음 문자에 대한 class를 예측해야 합니다.\n",
    "\n",
    "### loss \n",
    "해당 분류 작업에 대해 모델을 훈련시키기 위해 `crossentropy` loss 형태를 사용할 수 있습니다. 특히나, `sparse_categorical_crossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/backend/sparse_categorical_crossentropy) loss를 사용할 것인데, 해당 loss는 범주형 분류 작업을 위해 정수 타겟을 사용하기 때문입니다. 실제 타겟(`labels`)과 예측 타겟(`logits`)을 사용하여 loss를 계산하는 방식입니다.  \n",
    "\n",
    "### hyper parameter tuning \n",
    "시작값 제공, 최적의 파라미터는 여러분들이 찾아보세요~\n",
    "\n",
    "### optimizer and training operation \n",
    "optimizer와 epochs은 신경망 출력에 영향을 줄 수 있음 \n",
    "- 아래는 시도해볼만 한 optimizer\n",
    "- [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam?version=stable)\n",
    "- [`Adagrad`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad?version=stable) \n",
    "\n",
    "Backpropagation은 [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape)를 사용 \n",
    "\n",
    "훈련 동안 모델의 진행 상황을 출력하여 loss를 최소화하고 있는지에 대한 여부를 시각화함\n",
    "\n",
    "### Benchmarking \n",
    "1. No-trained model -> scalar loss : 4.418331 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (32, 100, 83)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.419138\n"
     ]
    }
   ],
   "source": [
    "### Defining the loss function ###\n",
    "'''TODO: define the loss function to compute and return the loss between\n",
    "    the true labels and predictions (logits). Set the argument from_logits=True.'''\n",
    "def compute_loss(labels, logits):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True) # TODO\n",
    "    return loss\n",
    "\n",
    "'''TODO: compute the loss using the true next characters from the example batch \n",
    "and the predictions from the untrained model several cells above'''\n",
    "example_batch_loss = compute_loss(y, pred)\n",
    "\n",
    "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "JQWUUhKotkAY"
   },
   "outputs": [],
   "source": [
    "### Hyperparameter setting and optimization ###\n",
    "\n",
    "# Optimization parameters:\n",
    "num_training_iterations = 2000  # Increase this to train longer\n",
    "batch_size = 4  # Experiment between 1 and 64\n",
    "seq_length = 100  # Experiment between 50 and 500\n",
    "learning_rate = 5e-3  # Experiment between 1e-5 and 1e-1\n",
    "\n",
    "# Model parameters: \n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256 \n",
    "rnn_units = 1024  # Experiment between 1 and 2048\n",
    "\n",
    "# Checkpoint location: \n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "F31vzJ_u66cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                               | 1/2000 [00:04<2:15:16,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  [61119 61550  8667 87169]\n",
      "input batch:  4\n",
      "output batch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 1/2000 [00:05<3:12:48,  5.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HYEONG~1\\AppData\\Local\\Temp/ipykernel_7704/4049686193.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Grab a batch and propagate it through the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorized_songs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# Update the progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Define optimizer and training operation ###\n",
    "\n",
    "'''TODO: instantiate a new model for training using the `build_model`\n",
    "  function and the hyperparameters created above.'''\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "'''TODO: instantiate an optimizer with its learning rate.\n",
    "  Checkout the tensorflow website for a list of supported optimizers.\n",
    "  https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/\n",
    "  Try using the Adam optimizer to start.'''\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y): \n",
    "    # Use tf.GradientTape()\n",
    "    with tf.GradientTape() as tape:\n",
    "        '''TODO: feed the current input into the model and generate predictions'''\n",
    "        y_hat = model(x)\n",
    "  \n",
    "        '''TODO: compute the loss!'''\n",
    "        loss = compute_loss(y, y_hat)\n",
    "\n",
    "    # Now, compute the gradients \n",
    "    '''TODO: complete the function call for gradient computation. \n",
    "      Remember that we want the gradient of the loss with respect all \n",
    "      of the model parameters. \n",
    "      HINT: use `model.trainable_variables` to get a list of all model\n",
    "      parameters.'''\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "  \n",
    "    # Apply the gradients to the optimizer so it can update the model accordingly\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "##################\n",
    "# Begin training!#\n",
    "##################\n",
    "\n",
    "history = []\n",
    "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "\n",
    "for iter in tqdm(range(num_training_iterations)):\n",
    "    # Grab a batch and propagate it through the network\n",
    "    x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
    "    loss = train_step(x_batch, y_batch)\n",
    "\n",
    "    # Update the progress bar\n",
    "    history.append(loss.numpy().mean())\n",
    "    plotter.plot(history)\n",
    "\n",
    "    # Update the model with the changed weights!\n",
    "    if iter % 100 == 0:     \n",
    "        model.save_weights(checkpoint_prefix)\n",
    "    \n",
    "    # Save the trained model and the weights\n",
    "    model.save_weights(checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## 2.6 Generate music using the RNN model : Inference\n",
    "\n",
    "음악을 만들어낼 때, 모델의 시작을 위해 몇 가지 시드를 공급해야 합니다. \n",
    "\n",
    "일단 생성된 시드를 가지고 나면, 훈련된 RNN을 사용하여 각각의 연속적인 문자를 반복적으로 예측할 수 있습니다. 보다 구체적으로, RNN은 가능한 연속적인 문자로 `softmax`를 출력한다는 것을 기억하자. 추론(Inference)을 하는 동안, 이런 분포로부터 반복적으로 표본을 추출한 다음 생성된 노래를 ABC 표기법으로 인코딩하는 데 샘플을 사용합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIPcXllKjkdr"
   },
   "source": [
    "### Restore the latest checkpoint\n",
    "\n",
    "- 추론(Inference) 단계를 간단하게 하기 위해서 공정 batch 크기는 1로 사용\n",
    "    - RNN의 state가 timestep에서 timestep으로 전달되는 방식 때문에, 모델은 오로지 한번 설정된 고정 batch 크기만을 수용할 수 있습니다. \n",
    "    - 다른 batch_size 모델을 실행하려면 rebuilding 해야 하고 훈련 중 마지막 checkpoint 이후의 가중치를 복원해야 함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (1, None, 256)            21248     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (1, None, 83)             85075     \n",
      "=================================================================\n",
      "Total params: 5,353,299\n",
      "Trainable params: 5,353,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''TODO: Rebuild the model using a batch_size=1'''\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "# Restore the model weights for the last checkpoint after training\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction procedure\n",
    "\n",
    "- \"시드\" 시작 문자열과 RNN state를 초기화 하고, 생성할 문자 수를 설정합니다.\n",
    "- 시작 문자열과 RNN state를 사용하여 다음 예측 문자에 대한 확률 분포를 얻습니다. \n",
    "- 예측 문자의 인덱스를 계산하기 위해 다항 분포 표본으로부터 샘플링합니다. 그런 다음 이 예측 문자를 모델의 다음 입력으로 사용합니다. \n",
    "- 각 time step에서, 업데이트 된 RNN state는 다시 모델에 공급되어, 다음 예측을 만들 때 더 많은 컨텍스트(context)를 갖게 됩니다. 다음 문자를 예측한 후, 업데이트 된 RNN states는 다시 모델에 공급되고, 이는 이전 예측으로부터 더 많은 정보를 얻기 때문에 데이터 속에서 시퀀스 종속성을 학습하게 하는 방법이 됩니다. \n",
    "\n",
    "![LSTM inference](https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_inference.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "### Prediction of a generated song ###\n",
    "\n",
    "def generate_text(model, start_string, generation_length=1000):\n",
    "    # Evaluation step (generating ABC text using the learned RNN model)\n",
    "\n",
    "    '''TODO: convert the start string to numbers (vectorize)'''\n",
    "    #input_eval = [vectorize_string(start_string)]\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    tqdm._instances.clear()\n",
    "\n",
    "    for i in tqdm(range(generation_length)):\n",
    "        '''TODO: evaluate the inputs and generate the next character predictions'''\n",
    "        predictions = model(input_eval)\n",
    "      \n",
    "        # Remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "      \n",
    "        '''TODO: use a multinomial distribution to sample'''\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "        # Pass the prediction along with the previous hidden state\n",
    "        #   as the next inputs to the model\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "        '''TODO: add the predicted character to the generated text!'''\n",
    "        # Hint: consider what format the prediction is in vs. the output\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    \n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ktovv0RFhrkn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 197.26it/s]\n"
     ]
    }
   ],
   "source": [
    "'''TODO: Use the model and the function defined above to generate ABC format text of length 1000!\n",
    "    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\n",
    "generated_text = generate_text(model, start_string=\"X\", generation_length=1000) # TODO\n",
    "# generated_text = generate_text('''TODO''', start_string=\"X\", generation_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM2Uma_-yVIq"
   },
   "source": [
    "### Play back the generated music!\n",
    "\n",
    "ABC notation text audio -> audio file 로 변환 후 생성된 노래 확인  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "LrOtG64bfLto"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 songs in text\n"
     ]
    }
   ],
   "source": [
    "### Play back generated songs ###\n",
    "\n",
    "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
    "\n",
    "for i, song in enumerate(generated_songs): \n",
    "    # Synthesize the waveform from a song\n",
    "    waveform = mdl.lab1.play_song(song)\n",
    "\n",
    "    # If its a valid song (correct syntax), lets play it! \n",
    "    if waveform:\n",
    "        print(\"Generated song\", i)\n",
    "        ipythondisplay.display(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "uoJsVjtCMunI"
   ],
   "name": "Part2_Music_Generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
